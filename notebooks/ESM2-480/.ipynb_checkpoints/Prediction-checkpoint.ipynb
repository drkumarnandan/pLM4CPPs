{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6105a668-7319-45df-add9-f47fd3f90b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "137/137 [==============================] - ETA: 0s - loss: 7.9489 - accuracy: 0.8241\n",
      "Epoch 1: val_accuracy improved from -inf to 0.25365, saving model to best_model_480.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 12s 71ms/step - loss: 7.9489 - accuracy: 0.8241 - val_loss: 4.6108 - val_accuracy: 0.2536 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.8727\n",
      "Epoch 2: val_accuracy did not improve from 0.25365\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.4941 - accuracy: 0.8727 - val_loss: 4.6010 - val_accuracy: 0.2536 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.8848\n",
      "Epoch 3: val_accuracy did not improve from 0.25365\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.4738 - accuracy: 0.8848 - val_loss: 4.4475 - val_accuracy: 0.2536 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.8816\n",
      "Epoch 4: val_accuracy improved from 0.25365 to 0.51642, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.4583 - accuracy: 0.8816 - val_loss: 0.9724 - val_accuracy: 0.5164 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.8843\n",
      "Epoch 5: val_accuracy improved from 0.51642 to 0.82664, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 0.4531 - accuracy: 0.8843 - val_loss: 0.4827 - val_accuracy: 0.8266 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.8757\n",
      "Epoch 6: val_accuracy improved from 0.82664 to 0.87591, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.4723 - accuracy: 0.8757 - val_loss: 0.3035 - val_accuracy: 0.8759 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.8950\n",
      "Epoch 7: val_accuracy improved from 0.87591 to 0.89507, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 0.4345 - accuracy: 0.8950 - val_loss: 0.3630 - val_accuracy: 0.8951 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4331 - accuracy: 0.8909\n",
      "Epoch 8: val_accuracy improved from 0.89507 to 0.90420, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.4331 - accuracy: 0.8909 - val_loss: 0.3112 - val_accuracy: 0.9042 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.8978\n",
      "Epoch 9: val_accuracy did not improve from 0.90420\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.4292 - accuracy: 0.8978 - val_loss: 0.3275 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4103 - accuracy: 0.8992\n",
      "Epoch 10: val_accuracy did not improve from 0.90420\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.4103 - accuracy: 0.8992 - val_loss: 0.3122 - val_accuracy: 0.9005 - lr: 0.0050\n",
      "Epoch 11/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3667 - accuracy: 0.9035\n",
      "Epoch 11: val_accuracy improved from 0.90420 to 0.91241, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.3667 - accuracy: 0.9035 - val_loss: 0.2874 - val_accuracy: 0.9124 - lr: 0.0050\n",
      "Epoch 12/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3737 - accuracy: 0.9090\n",
      "Epoch 12: val_accuracy did not improve from 0.91241\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.3737 - accuracy: 0.9090 - val_loss: 0.3120 - val_accuracy: 0.9088 - lr: 0.0050\n",
      "Epoch 13/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.9103\n",
      "Epoch 13: val_accuracy did not improve from 0.91241\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.3695 - accuracy: 0.9103 - val_loss: 0.2909 - val_accuracy: 0.8996 - lr: 0.0050\n",
      "Epoch 14/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3671 - accuracy: 0.9055\n",
      "Epoch 14: val_accuracy did not improve from 0.91241\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.3671 - accuracy: 0.9055 - val_loss: 0.3739 - val_accuracy: 0.9042 - lr: 0.0050\n",
      "Epoch 15/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.9112\n",
      "Epoch 15: val_accuracy did not improve from 0.91241\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.3859 - accuracy: 0.9112 - val_loss: 0.2976 - val_accuracy: 0.9042 - lr: 0.0050\n",
      "Epoch 16/100\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3661 - accuracy: 0.9106\n",
      "Epoch 16: val_accuracy did not improve from 0.91241\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.3663 - accuracy: 0.9103 - val_loss: 0.2836 - val_accuracy: 0.9124 - lr: 0.0050\n",
      "Epoch 17/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3568 - accuracy: 0.9131\n",
      "Epoch 17: val_accuracy did not improve from 0.91241\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.3568 - accuracy: 0.9131 - val_loss: 0.2706 - val_accuracy: 0.9015 - lr: 0.0050\n",
      "Epoch 18/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3581 - accuracy: 0.9179\n",
      "Epoch 18: val_accuracy improved from 0.91241 to 0.91697, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.3581 - accuracy: 0.9179 - val_loss: 0.2635 - val_accuracy: 0.9170 - lr: 0.0050\n",
      "Epoch 19/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.9135\n",
      "Epoch 19: val_accuracy did not improve from 0.91697\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.3496 - accuracy: 0.9135 - val_loss: 0.2864 - val_accuracy: 0.9106 - lr: 0.0050\n",
      "Epoch 20/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3118 - accuracy: 0.9204\n",
      "Epoch 20: val_accuracy did not improve from 0.91697\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.3118 - accuracy: 0.9204 - val_loss: 0.2866 - val_accuracy: 0.9088 - lr: 0.0025\n",
      "Epoch 21/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3110 - accuracy: 0.9197\n",
      "Epoch 21: val_accuracy did not improve from 0.91697\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.3110 - accuracy: 0.9197 - val_loss: 0.2795 - val_accuracy: 0.9051 - lr: 0.0025\n",
      "Epoch 22/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3022 - accuracy: 0.9229\n",
      "Epoch 22: val_accuracy did not improve from 0.91697\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.3022 - accuracy: 0.9229 - val_loss: 0.2718 - val_accuracy: 0.9115 - lr: 0.0025\n",
      "Epoch 23/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2960 - accuracy: 0.9224\n",
      "Epoch 23: val_accuracy did not improve from 0.91697\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.2960 - accuracy: 0.9224 - val_loss: 0.2639 - val_accuracy: 0.9142 - lr: 0.0025\n",
      "Epoch 24/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.9304\n",
      "Epoch 24: val_accuracy did not improve from 0.91697\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.2844 - accuracy: 0.9304 - val_loss: 0.2833 - val_accuracy: 0.9133 - lr: 0.0025\n",
      "Epoch 25/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.9258\n",
      "Epoch 25: val_accuracy did not improve from 0.91697\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.2811 - accuracy: 0.9258 - val_loss: 0.2889 - val_accuracy: 0.9051 - lr: 0.0025\n",
      "Epoch 26/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.9293\n",
      "Epoch 26: val_accuracy did not improve from 0.91697\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.2927 - accuracy: 0.9293 - val_loss: 0.2609 - val_accuracy: 0.9142 - lr: 0.0025\n",
      "Epoch 27/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2930 - accuracy: 0.9295\n",
      "Epoch 27: val_accuracy did not improve from 0.91697\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.2930 - accuracy: 0.9295 - val_loss: 0.2788 - val_accuracy: 0.9161 - lr: 0.0025\n",
      "Epoch 28/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.9361\n",
      "Epoch 28: val_accuracy did not improve from 0.91697\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.2721 - accuracy: 0.9361 - val_loss: 0.2906 - val_accuracy: 0.9161 - lr: 0.0025\n",
      "Epoch 29/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.9300\n",
      "Epoch 29: val_accuracy improved from 0.91697 to 0.91971, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 10s 69ms/step - loss: 0.2818 - accuracy: 0.9300 - val_loss: 0.2962 - val_accuracy: 0.9197 - lr: 0.0025\n",
      "Epoch 30/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2497 - accuracy: 0.9347\n",
      "Epoch 30: val_accuracy did not improve from 0.91971\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.2497 - accuracy: 0.9347 - val_loss: 0.2774 - val_accuracy: 0.9124 - lr: 0.0012\n",
      "Epoch 31/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.9357\n",
      "Epoch 31: val_accuracy did not improve from 0.91971\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.2500 - accuracy: 0.9357 - val_loss: 0.2908 - val_accuracy: 0.9170 - lr: 0.0012\n",
      "Epoch 32/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.9418\n",
      "Epoch 32: val_accuracy did not improve from 0.91971\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.2289 - accuracy: 0.9418 - val_loss: 0.2983 - val_accuracy: 0.9197 - lr: 0.0012\n",
      "Epoch 33/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.9432\n",
      "Epoch 33: val_accuracy did not improve from 0.91971\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.2317 - accuracy: 0.9432 - val_loss: 0.2931 - val_accuracy: 0.9188 - lr: 0.0012\n",
      "Epoch 34/100\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.2325 - accuracy: 0.9467\n",
      "Epoch 34: val_accuracy improved from 0.91971 to 0.92062, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 0.2327 - accuracy: 0.9466 - val_loss: 0.3214 - val_accuracy: 0.9206 - lr: 0.0012\n",
      "Epoch 35/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.9459\n",
      "Epoch 35: val_accuracy did not improve from 0.92062\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.2227 - accuracy: 0.9459 - val_loss: 0.3113 - val_accuracy: 0.9197 - lr: 0.0012\n",
      "Epoch 36/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.9457\n",
      "Epoch 36: val_accuracy did not improve from 0.92062\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.2259 - accuracy: 0.9457 - val_loss: 0.3130 - val_accuracy: 0.9197 - lr: 0.0012\n",
      "Epoch 37/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.9450\n",
      "Epoch 37: val_accuracy improved from 0.92062 to 0.92153, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.2286 - accuracy: 0.9450 - val_loss: 0.3132 - val_accuracy: 0.9215 - lr: 0.0012\n",
      "Epoch 38/100\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.2100 - accuracy: 0.9472\n",
      "Epoch 38: val_accuracy improved from 0.92153 to 0.92245, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.2093 - accuracy: 0.9475 - val_loss: 0.2933 - val_accuracy: 0.9224 - lr: 0.0012\n",
      "Epoch 39/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.9500\n",
      "Epoch 39: val_accuracy did not improve from 0.92245\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.2109 - accuracy: 0.9500 - val_loss: 0.3673 - val_accuracy: 0.9170 - lr: 0.0012\n",
      "Epoch 40/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1983 - accuracy: 0.9519\n",
      "Epoch 40: val_accuracy improved from 0.92245 to 0.92609, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.1983 - accuracy: 0.9519 - val_loss: 0.3487 - val_accuracy: 0.9261 - lr: 6.2500e-04\n",
      "Epoch 41/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1973 - accuracy: 0.9516\n",
      "Epoch 41: val_accuracy did not improve from 0.92609\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1973 - accuracy: 0.9516 - val_loss: 0.3372 - val_accuracy: 0.9234 - lr: 6.2500e-04\n",
      "Epoch 42/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1934 - accuracy: 0.9519\n",
      "Epoch 42: val_accuracy did not improve from 0.92609\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.1934 - accuracy: 0.9519 - val_loss: 0.3532 - val_accuracy: 0.9261 - lr: 6.2500e-04\n",
      "Epoch 43/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1905 - accuracy: 0.9567\n",
      "Epoch 43: val_accuracy improved from 0.92609 to 0.92701, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.1905 - accuracy: 0.9567 - val_loss: 0.3627 - val_accuracy: 0.9270 - lr: 6.2500e-04\n",
      "Epoch 44/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9537\n",
      "Epoch 44: val_accuracy did not improve from 0.92701\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.1861 - accuracy: 0.9537 - val_loss: 0.3567 - val_accuracy: 0.9252 - lr: 6.2500e-04\n",
      "Epoch 45/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.9560\n",
      "Epoch 45: val_accuracy did not improve from 0.92701\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.1822 - accuracy: 0.9560 - val_loss: 0.3574 - val_accuracy: 0.9234 - lr: 6.2500e-04\n",
      "Epoch 46/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.9571\n",
      "Epoch 46: val_accuracy improved from 0.92701 to 0.92792, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 0.1844 - accuracy: 0.9571 - val_loss: 0.3550 - val_accuracy: 0.9279 - lr: 6.2500e-04\n",
      "Epoch 47/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1834 - accuracy: 0.9557\n",
      "Epoch 47: val_accuracy did not improve from 0.92792\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1834 - accuracy: 0.9557 - val_loss: 0.3655 - val_accuracy: 0.9261 - lr: 6.2500e-04\n",
      "Epoch 48/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.9541\n",
      "Epoch 48: val_accuracy did not improve from 0.92792\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1839 - accuracy: 0.9541 - val_loss: 0.3519 - val_accuracy: 0.9279 - lr: 6.2500e-04\n",
      "Epoch 49/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9603\n",
      "Epoch 49: val_accuracy did not improve from 0.92792\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.1685 - accuracy: 0.9603 - val_loss: 0.3395 - val_accuracy: 0.9234 - lr: 6.2500e-04\n",
      "Epoch 50/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.9596\n",
      "Epoch 50: val_accuracy did not improve from 0.92792\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1701 - accuracy: 0.9596 - val_loss: 0.3623 - val_accuracy: 0.9279 - lr: 3.1250e-04\n",
      "Epoch 51/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.9592\n",
      "Epoch 51: val_accuracy improved from 0.92792 to 0.92883, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 0.1707 - accuracy: 0.9592 - val_loss: 0.3674 - val_accuracy: 0.9288 - lr: 3.1250e-04\n",
      "Epoch 52/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9624\n",
      "Epoch 52: val_accuracy did not improve from 0.92883\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.1627 - accuracy: 0.9624 - val_loss: 0.3763 - val_accuracy: 0.9279 - lr: 3.1250e-04\n",
      "Epoch 53/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1603 - accuracy: 0.9630\n",
      "Epoch 53: val_accuracy did not improve from 0.92883\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1603 - accuracy: 0.9630 - val_loss: 0.3878 - val_accuracy: 0.9261 - lr: 3.1250e-04\n",
      "Epoch 54/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.9576\n",
      "Epoch 54: val_accuracy did not improve from 0.92883\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.1648 - accuracy: 0.9576 - val_loss: 0.3861 - val_accuracy: 0.9252 - lr: 3.1250e-04\n",
      "Epoch 55/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.9651\n",
      "Epoch 55: val_accuracy did not improve from 0.92883\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1550 - accuracy: 0.9651 - val_loss: 0.3921 - val_accuracy: 0.9270 - lr: 3.1250e-04\n",
      "Epoch 56/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9628\n",
      "Epoch 56: val_accuracy did not improve from 0.92883\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1589 - accuracy: 0.9628 - val_loss: 0.4095 - val_accuracy: 0.9270 - lr: 3.1250e-04\n",
      "Epoch 57/100\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.1545 - accuracy: 0.9630\n",
      "Epoch 57: val_accuracy did not improve from 0.92883\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1544 - accuracy: 0.9630 - val_loss: 0.4088 - val_accuracy: 0.9270 - lr: 3.1250e-04\n",
      "Epoch 58/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9642\n",
      "Epoch 58: val_accuracy did not improve from 0.92883\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.1485 - accuracy: 0.9642 - val_loss: 0.3947 - val_accuracy: 0.9288 - lr: 3.1250e-04\n",
      "Epoch 59/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.9635\n",
      "Epoch 59: val_accuracy improved from 0.92883 to 0.92974, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.1573 - accuracy: 0.9635 - val_loss: 0.4172 - val_accuracy: 0.9297 - lr: 3.1250e-04\n",
      "Epoch 60/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.9649\n",
      "Epoch 60: val_accuracy did not improve from 0.92974\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.1536 - accuracy: 0.9649 - val_loss: 0.4104 - val_accuracy: 0.9288 - lr: 1.5625e-04\n",
      "Epoch 61/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.9603\n",
      "Epoch 61: val_accuracy did not improve from 0.92974\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.1609 - accuracy: 0.9603 - val_loss: 0.4185 - val_accuracy: 0.9288 - lr: 1.5625e-04\n",
      "Epoch 62/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.9630\n",
      "Epoch 62: val_accuracy did not improve from 0.92974\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1479 - accuracy: 0.9630 - val_loss: 0.4256 - val_accuracy: 0.9261 - lr: 1.5625e-04\n",
      "Epoch 63/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.9624\n",
      "Epoch 63: val_accuracy did not improve from 0.92974\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1450 - accuracy: 0.9624 - val_loss: 0.4254 - val_accuracy: 0.9279 - lr: 1.5625e-04\n",
      "Epoch 64/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9628\n",
      "Epoch 64: val_accuracy did not improve from 0.92974\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1442 - accuracy: 0.9628 - val_loss: 0.4269 - val_accuracy: 0.9270 - lr: 1.5625e-04\n",
      "Epoch 65/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9640\n",
      "Epoch 65: val_accuracy did not improve from 0.92974\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.1477 - accuracy: 0.9640 - val_loss: 0.4249 - val_accuracy: 0.9279 - lr: 1.5625e-04\n",
      "Epoch 66/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1516 - accuracy: 0.9637\n",
      "Epoch 66: val_accuracy did not improve from 0.92974\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1516 - accuracy: 0.9637 - val_loss: 0.4322 - val_accuracy: 0.9288 - lr: 1.5625e-04\n",
      "Epoch 67/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9665\n",
      "Epoch 67: val_accuracy improved from 0.92974 to 0.93066, saving model to best_model_480.h5\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.1445 - accuracy: 0.9665 - val_loss: 0.4216 - val_accuracy: 0.9307 - lr: 1.5625e-04\n",
      "Epoch 68/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9633\n",
      "Epoch 68: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.1525 - accuracy: 0.9633 - val_loss: 0.4322 - val_accuracy: 0.9279 - lr: 1.5625e-04\n",
      "Epoch 69/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.9649\n",
      "Epoch 69: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 0.1429 - accuracy: 0.9649 - val_loss: 0.4238 - val_accuracy: 0.9270 - lr: 1.5625e-04\n",
      "Epoch 70/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1366 - accuracy: 0.9683\n",
      "Epoch 70: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 0.1366 - accuracy: 0.9683 - val_loss: 0.4380 - val_accuracy: 0.9297 - lr: 7.8125e-05\n",
      "Epoch 71/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9674\n",
      "Epoch 71: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 0.1396 - accuracy: 0.9674 - val_loss: 0.4373 - val_accuracy: 0.9307 - lr: 7.8125e-05\n",
      "Epoch 72/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9644\n",
      "Epoch 72: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 70ms/step - loss: 0.1413 - accuracy: 0.9644 - val_loss: 0.4408 - val_accuracy: 0.9297 - lr: 7.8125e-05\n",
      "Epoch 73/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.9662\n",
      "Epoch 73: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 0.1379 - accuracy: 0.9662 - val_loss: 0.4469 - val_accuracy: 0.9297 - lr: 7.8125e-05\n",
      "Epoch 74/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1467 - accuracy: 0.9651\n",
      "Epoch 74: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 70ms/step - loss: 0.1467 - accuracy: 0.9651 - val_loss: 0.4522 - val_accuracy: 0.9288 - lr: 7.8125e-05\n",
      "Epoch 75/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.9655\n",
      "Epoch 75: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 70ms/step - loss: 0.1448 - accuracy: 0.9655 - val_loss: 0.4511 - val_accuracy: 0.9288 - lr: 7.8125e-05\n",
      "Epoch 76/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.9708\n",
      "Epoch 76: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 70ms/step - loss: 0.1310 - accuracy: 0.9708 - val_loss: 0.4611 - val_accuracy: 0.9279 - lr: 7.8125e-05\n",
      "Epoch 77/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9665\n",
      "Epoch 77: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 70ms/step - loss: 0.1338 - accuracy: 0.9665 - val_loss: 0.4597 - val_accuracy: 0.9288 - lr: 7.8125e-05\n",
      "Epoch 78/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.9649\n",
      "Epoch 78: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 0.1427 - accuracy: 0.9649 - val_loss: 0.4618 - val_accuracy: 0.9288 - lr: 7.8125e-05\n",
      "Epoch 79/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9676\n",
      "Epoch 79: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 0.1321 - accuracy: 0.9676 - val_loss: 0.4618 - val_accuracy: 0.9288 - lr: 7.8125e-05\n",
      "Epoch 80/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.9646\n",
      "Epoch 80: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 0.1367 - accuracy: 0.9646 - val_loss: 0.4625 - val_accuracy: 0.9297 - lr: 3.9062e-05\n",
      "Epoch 81/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9662\n",
      "Epoch 81: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 0.1390 - accuracy: 0.9662 - val_loss: 0.4615 - val_accuracy: 0.9288 - lr: 3.9062e-05\n",
      "Epoch 82/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.9676\n",
      "Epoch 82: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 73ms/step - loss: 0.1299 - accuracy: 0.9676 - val_loss: 0.4658 - val_accuracy: 0.9297 - lr: 3.9062e-05\n",
      "Epoch 83/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9674\n",
      "Epoch 83: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 73ms/step - loss: 0.1312 - accuracy: 0.9674 - val_loss: 0.4745 - val_accuracy: 0.9297 - lr: 3.9062e-05\n",
      "Epoch 84/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.9637\n",
      "Epoch 84: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 72ms/step - loss: 0.1491 - accuracy: 0.9637 - val_loss: 0.4623 - val_accuracy: 0.9288 - lr: 3.9062e-05\n",
      "Epoch 85/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.9669\n",
      "Epoch 85: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 0.1358 - accuracy: 0.9669 - val_loss: 0.4630 - val_accuracy: 0.9279 - lr: 3.9062e-05\n",
      "Epoch 86/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.9685\n",
      "Epoch 86: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 0.1308 - accuracy: 0.9685 - val_loss: 0.4653 - val_accuracy: 0.9297 - lr: 3.9062e-05\n",
      "Epoch 87/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9685Restoring model weights from the end of the best epoch: 67.\n",
      "\n",
      "Epoch 87: val_accuracy did not improve from 0.93066\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 0.1342 - accuracy: 0.9685 - val_loss: 0.4671 - val_accuracy: 0.9297 - lr: 3.9062e-05\n",
      "Epoch 87: early stopping\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t12_35M_UR50D_unified_480_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "def build_model(input_shape):\n",
    "    input = Input(input_shape)\n",
    "    x = Conv1D(64, 5, strides=1, padding='same')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = MaxPooling1D(2, padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv1D(128, 5, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = MaxPooling1D(2, padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lr = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10\n",
    "    lr = initial_lr * np.power(drop, np.floor((1 + epoch) / epochs_drop))\n",
    "    return lr\n",
    "\n",
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "    input_shape = (480, 1)\n",
    "    model = build_model(input_shape)\n",
    "    \n",
    "    # Optimizer\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "    early_stop = EarlyStopping(monitor='val_accuracy', patience=20, verbose=1, restore_best_weights=True)\n",
    "    mc = ModelCheckpoint('best_model_480.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "    callbacks_list = [lrate, early_stop, mc]\n",
    "    \n",
    "    class_weight = {0: 1, 1: 2}  # Adjust the weights as needed\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, callbacks=callbacks_list, batch_size=32, class_weight=class_weight)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Load the best model\n",
    "saved_model = load_model('best_model_480.h5')\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_probas):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_probas > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        \n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5141fb51-a6ef-4f76-91b2-ac2fb5a3d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 12ms/step\n",
      "\n",
      "Optimized Test Dataset Results:\n",
      "Accuracy (ACC): 0.9306569343065694\n",
      "Balanced Accuracy (BACC): 0.9072399781885983\n",
      "Sensitivity (Sn): 0.8597122302158273\n",
      "Specificity (Sp): 0.9547677261613692\n",
      "MCC: 0.8164281748282612\n",
      "AUC: 0.9072399781885981\n",
      "True Positives (TP): 239\n",
      "False Positives (FP): 37\n",
      "True Negatives (TN): 781\n",
      "False Negatives (FN): 39\n",
      "Total Positive: 278\n",
      "Total Negative: 818\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test dataset\n",
    "predicted_probas_test = saved_model.predict(X_test, batch_size=32)\n",
    "best_threshold_test, best_mcc_test = optimize_threshold(y_test, predicted_probas_test)\n",
    "predicted_classes_test = (predicted_probas_test > best_threshold_test).astype(int)\n",
    "\n",
    "# Calculate metrics for the test dataset with optimized threshold\n",
    "accuracy_test = accuracy_score(y_test, predicted_classes_test)\n",
    "sensitivity_test = recall_score(y_test, predicted_classes_test)  # Sensitivity (Recall)\n",
    "TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, predicted_classes_test).ravel()\n",
    "specificity_test = TN_test / (TN_test + FP_test)  # Corrected Specificity calculation\n",
    "MCC_test = matthews_corrcoef(y_test, predicted_classes_test)\n",
    "auc_test = roc_auc_score(y_test, predicted_classes_test)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "# Print the adjusted results for the test dataset\n",
    "print(\"\\nOptimized Test Dataset Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "print(f\"Specificity (Sp): {specificity_test}\")\n",
    "print(f\"MCC: {MCC_test}\")\n",
    "print(f\"AUC: {auc_test}\")\n",
    "print(f\"True Positives (TP): {TP_test}\")\n",
    "print(f\"False Positives (FP): {FP_test}\")\n",
    "print(f\"True Negatives (TN): {TN_test}\")\n",
    "print(f\"False Negatives (FN): {FN_test}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive = np.sum(y_test)\n",
    "total_negative = len(y_test) - total_positive\n",
    "print(f\"Total Positive: {total_positive}\")\n",
    "print(f\"Total Negative: {total_negative}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0232f1-1e5f-4a1a-9c9c-46b4dbede579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step\n",
      "\n",
      "Optimized External Dataset (KELM) Results:\n",
      "Accuracy (ACC): 0.8645833333333334\n",
      "Balanced Accuracy (BACC): 0.8645833333333334\n",
      "Sensitivity (Sn): 0.8020833333333334\n",
      "Specificity (Sp): 0.9270833333333334\n",
      "MCC: 0.7349309197401641\n",
      "AUC: 0.8645833333333335\n",
      "True Positives (TP): 77\n",
      "False Positives (FP): 7\n",
      "True Negatives (TN): 89\n",
      "False Negatives (FN): 19\n",
      "Total Positive: 96\n",
      "Total Negative: 96\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the external dataset (KELM)\n",
    "dataset_external = pd.read_csv('kelm_dataset.csv', na_filter=False)\n",
    "X_external_data_name = 'kelm_dataset_esm2_t12_35M_UR50D_unified_480_dimension.csv'\n",
    "X_external_data = pd.read_csv(X_external_data_name, header=0, index_col=0, delimiter=',')\n",
    "X_external = np.array(X_external_data)\n",
    "y_external = np.array(dataset_external['label'])\n",
    "\n",
    "# Normalize the external dataset\n",
    "X_external_normalized = scaler.transform(X_external)\n",
    "\n",
    "# Predict probabilities for external dataset\n",
    "predicted_probas_ext = saved_model.predict(X_external_normalized, batch_size=32)\n",
    "best_threshold_ext, best_mcc_ext = optimize_threshold(y_external, predicted_probas_ext)\n",
    "predicted_classes_ext = (predicted_probas_ext > best_threshold_ext).astype(int)\n",
    "\n",
    "# Calculate metrics for the external dataset with optimized threshold\n",
    "accuracy_ext = accuracy_score(y_external, predicted_classes_ext)\n",
    "sensitivity_ext = recall_score(y_external, predicted_classes_ext)  # Sensitivity (Recall)\n",
    "TN_ext, FP_ext, FN_ext, TP_ext = confusion_matrix(y_external, predicted_classes_ext).ravel()\n",
    "specificity_ext = TN_ext / (TN_ext + FP_ext)  # Corrected Specificity calculation\n",
    "MCC_ext = matthews_corrcoef(y_external, predicted_classes_ext)\n",
    "auc_ext = roc_auc_score(y_external, predicted_classes_ext)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_ext = (sensitivity_ext + specificity_ext) / 2\n",
    "\n",
    "# Print the adjusted results for the external dataset\n",
    "print(\"\\nOptimized External Dataset (KELM) Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_ext}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_ext}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_ext}\")\n",
    "print(f\"Specificity (Sp): {specificity_ext}\")\n",
    "print(f\"MCC: {MCC_ext}\")\n",
    "print(f\"AUC: {auc_ext}\")\n",
    "print(f\"True Positives (TP): {TP_ext}\")\n",
    "print(f\"False Positives (FP): {FP_ext}\")\n",
    "print(f\"True Negatives (TN): {TN_ext}\")\n",
    "print(f\"False Negatives (FN): {FN_ext}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive_ext = np.sum(y_external)\n",
    "total_negative_ext = len(y_external) - total_positive_ext\n",
    "print(f\"Total Positive: {total_positive_ext}\")\n",
    "print(f\"Total Negative: {total_negative_ext}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
