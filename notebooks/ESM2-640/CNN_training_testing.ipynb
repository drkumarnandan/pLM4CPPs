{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6105a668-7319-45df-add9-f47fd3f90b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 10.5230 - accuracy: 0.8045\n",
      "Epoch 1: val_accuracy improved from -inf to 0.86405, saving model to best_model_640.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 14s 94ms/step - loss: 10.5230 - accuracy: 0.8045 - val_loss: 0.6476 - val_accuracy: 0.8641 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.8658\n",
      "Epoch 2: val_accuracy improved from 0.86405 to 0.86496, saving model to best_model_640.h5\n",
      "137/137 [==============================] - 13s 92ms/step - loss: 0.4980 - accuracy: 0.8658 - val_loss: 0.5574 - val_accuracy: 0.8650 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.8811\n",
      "Epoch 3: val_accuracy improved from 0.86496 to 0.88504, saving model to best_model_640.h5\n",
      "137/137 [==============================] - 12s 90ms/step - loss: 0.4565 - accuracy: 0.8811 - val_loss: 0.4379 - val_accuracy: 0.8850 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4482 - accuracy: 0.8825\n",
      "Epoch 4: val_accuracy improved from 0.88504 to 0.89599, saving model to best_model_640.h5\n",
      "137/137 [==============================] - 12s 91ms/step - loss: 0.4482 - accuracy: 0.8825 - val_loss: 0.3262 - val_accuracy: 0.8960 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.8814\n",
      "Epoch 5: val_accuracy improved from 0.89599 to 0.89690, saving model to best_model_640.h5\n",
      "137/137 [==============================] - 12s 90ms/step - loss: 0.4283 - accuracy: 0.8814 - val_loss: 0.3172 - val_accuracy: 0.8969 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4252 - accuracy: 0.8907\n",
      "Epoch 6: val_accuracy did not improve from 0.89690\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.4252 - accuracy: 0.8907 - val_loss: 0.3227 - val_accuracy: 0.8932 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4293 - accuracy: 0.8905\n",
      "Epoch 7: val_accuracy did not improve from 0.89690\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.4293 - accuracy: 0.8905 - val_loss: 0.3028 - val_accuracy: 0.8951 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.8919\n",
      "Epoch 8: val_accuracy did not improve from 0.89690\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.4447 - accuracy: 0.8919 - val_loss: 0.3151 - val_accuracy: 0.8932 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.8919\n",
      "Epoch 9: val_accuracy improved from 0.89690 to 0.90055, saving model to best_model_640.h5\n",
      "137/137 [==============================] - 12s 90ms/step - loss: 0.4355 - accuracy: 0.8919 - val_loss: 0.2846 - val_accuracy: 0.9005 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.8982\n",
      "Epoch 10: val_accuracy did not improve from 0.90055\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.3887 - accuracy: 0.8982 - val_loss: 0.3000 - val_accuracy: 0.8996 - lr: 0.0050\n",
      "Epoch 11/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.9071\n",
      "Epoch 11: val_accuracy improved from 0.90055 to 0.90693, saving model to best_model_640.h5\n",
      "137/137 [==============================] - 12s 90ms/step - loss: 0.3699 - accuracy: 0.9071 - val_loss: 0.3009 - val_accuracy: 0.9069 - lr: 0.0050\n",
      "Epoch 12/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.9008\n",
      "Epoch 12: val_accuracy improved from 0.90693 to 0.91332, saving model to best_model_640.h5\n",
      "137/137 [==============================] - 12s 90ms/step - loss: 0.3833 - accuracy: 0.9008 - val_loss: 0.3147 - val_accuracy: 0.9133 - lr: 0.0050\n",
      "Epoch 13/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.9119\n",
      "Epoch 13: val_accuracy did not improve from 0.91332\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.3663 - accuracy: 0.9119 - val_loss: 0.3239 - val_accuracy: 0.8978 - lr: 0.0050\n",
      "Epoch 14/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.9128\n",
      "Epoch 14: val_accuracy did not improve from 0.91332\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.3476 - accuracy: 0.9128 - val_loss: 0.3184 - val_accuracy: 0.8905 - lr: 0.0050\n",
      "Epoch 15/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.9099\n",
      "Epoch 15: val_accuracy did not improve from 0.91332\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.3485 - accuracy: 0.9099 - val_loss: 0.3163 - val_accuracy: 0.9097 - lr: 0.0050\n",
      "Epoch 16/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.9078\n",
      "Epoch 16: val_accuracy did not improve from 0.91332\n",
      "137/137 [==============================] - 12s 89ms/step - loss: 0.3548 - accuracy: 0.9078 - val_loss: 0.3441 - val_accuracy: 0.8942 - lr: 0.0050\n",
      "Epoch 17/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3214 - accuracy: 0.9170\n",
      "Epoch 17: val_accuracy did not improve from 0.91332\n",
      "137/137 [==============================] - 12s 90ms/step - loss: 0.3214 - accuracy: 0.9170 - val_loss: 0.2752 - val_accuracy: 0.9106 - lr: 0.0050\n",
      "Epoch 18/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.9135\n",
      "Epoch 18: val_accuracy did not improve from 0.91332\n",
      "137/137 [==============================] - 12s 89ms/step - loss: 0.3207 - accuracy: 0.9135 - val_loss: 0.2933 - val_accuracy: 0.9078 - lr: 0.0050\n",
      "Epoch 19/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.9227\n",
      "Epoch 19: val_accuracy improved from 0.91332 to 0.91606, saving model to best_model_640.h5\n",
      "137/137 [==============================] - 12s 91ms/step - loss: 0.3076 - accuracy: 0.9227 - val_loss: 0.2987 - val_accuracy: 0.9161 - lr: 0.0050\n",
      "Epoch 20/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.9247\n",
      "Epoch 20: val_accuracy did not improve from 0.91606\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.2887 - accuracy: 0.9247 - val_loss: 0.2768 - val_accuracy: 0.9161 - lr: 0.0025\n",
      "Epoch 21/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.9240\n",
      "Epoch 21: val_accuracy did not improve from 0.91606\n",
      "137/137 [==============================] - 12s 87ms/step - loss: 0.2823 - accuracy: 0.9240 - val_loss: 0.2723 - val_accuracy: 0.9161 - lr: 0.0025\n",
      "Epoch 22/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2657 - accuracy: 0.9325\n",
      "Epoch 22: val_accuracy did not improve from 0.91606\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.2657 - accuracy: 0.9325 - val_loss: 0.2971 - val_accuracy: 0.9115 - lr: 0.0025\n",
      "Epoch 23/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2770 - accuracy: 0.9309\n",
      "Epoch 23: val_accuracy did not improve from 0.91606\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.2770 - accuracy: 0.9309 - val_loss: 0.3265 - val_accuracy: 0.9106 - lr: 0.0025\n",
      "Epoch 24/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.9306\n",
      "Epoch 24: val_accuracy improved from 0.91606 to 0.92336, saving model to best_model_640.h5\n",
      "137/137 [==============================] - 12s 90ms/step - loss: 0.2749 - accuracy: 0.9306 - val_loss: 0.2887 - val_accuracy: 0.9234 - lr: 0.0025\n",
      "Epoch 25/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2649 - accuracy: 0.9311\n",
      "Epoch 25: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.2649 - accuracy: 0.9311 - val_loss: 0.3278 - val_accuracy: 0.8996 - lr: 0.0025\n",
      "Epoch 26/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2538 - accuracy: 0.9338\n",
      "Epoch 26: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.2538 - accuracy: 0.9338 - val_loss: 0.3045 - val_accuracy: 0.9088 - lr: 0.0025\n",
      "Epoch 27/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9391\n",
      "Epoch 27: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.2449 - accuracy: 0.9391 - val_loss: 0.3388 - val_accuracy: 0.8996 - lr: 0.0025\n",
      "Epoch 28/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2532 - accuracy: 0.9318\n",
      "Epoch 28: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.2532 - accuracy: 0.9318 - val_loss: 0.3346 - val_accuracy: 0.9060 - lr: 0.0025\n",
      "Epoch 29/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2502 - accuracy: 0.9345\n",
      "Epoch 29: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 87ms/step - loss: 0.2502 - accuracy: 0.9345 - val_loss: 0.2961 - val_accuracy: 0.9197 - lr: 0.0025\n",
      "Epoch 30/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.9448\n",
      "Epoch 30: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.2156 - accuracy: 0.9448 - val_loss: 0.3459 - val_accuracy: 0.9088 - lr: 0.0012\n",
      "Epoch 31/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.9414\n",
      "Epoch 31: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.2254 - accuracy: 0.9414 - val_loss: 0.3181 - val_accuracy: 0.9170 - lr: 0.0012\n",
      "Epoch 32/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.9425\n",
      "Epoch 32: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.2005 - accuracy: 0.9425 - val_loss: 0.3275 - val_accuracy: 0.9188 - lr: 0.0012\n",
      "Epoch 33/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.9478\n",
      "Epoch 33: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 87ms/step - loss: 0.2054 - accuracy: 0.9478 - val_loss: 0.3425 - val_accuracy: 0.9124 - lr: 0.0012\n",
      "Epoch 34/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.9496\n",
      "Epoch 34: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 87ms/step - loss: 0.1920 - accuracy: 0.9496 - val_loss: 0.3404 - val_accuracy: 0.9151 - lr: 0.0012\n",
      "Epoch 35/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1918 - accuracy: 0.9468\n",
      "Epoch 35: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.1918 - accuracy: 0.9468 - val_loss: 0.3630 - val_accuracy: 0.9133 - lr: 0.0012\n",
      "Epoch 36/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2037 - accuracy: 0.9466\n",
      "Epoch 36: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 87ms/step - loss: 0.2037 - accuracy: 0.9466 - val_loss: 0.2966 - val_accuracy: 0.9197 - lr: 0.0012\n",
      "Epoch 37/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.9489\n",
      "Epoch 37: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 87ms/step - loss: 0.1970 - accuracy: 0.9489 - val_loss: 0.3798 - val_accuracy: 0.9179 - lr: 0.0012\n",
      "Epoch 38/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9544\n",
      "Epoch 38: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 87ms/step - loss: 0.1803 - accuracy: 0.9544 - val_loss: 0.3734 - val_accuracy: 0.9097 - lr: 0.0012\n",
      "Epoch 39/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1949 - accuracy: 0.9478\n",
      "Epoch 39: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 87ms/step - loss: 0.1949 - accuracy: 0.9478 - val_loss: 0.4213 - val_accuracy: 0.9051 - lr: 0.0012\n",
      "Epoch 40/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.9528\n",
      "Epoch 40: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.1701 - accuracy: 0.9528 - val_loss: 0.3724 - val_accuracy: 0.9188 - lr: 6.2500e-04\n",
      "Epoch 41/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9525\n",
      "Epoch 41: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.1764 - accuracy: 0.9525 - val_loss: 0.3868 - val_accuracy: 0.9179 - lr: 6.2500e-04\n",
      "Epoch 42/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9564\n",
      "Epoch 42: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.1770 - accuracy: 0.9564 - val_loss: 0.3790 - val_accuracy: 0.9215 - lr: 6.2500e-04\n",
      "Epoch 43/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.9555\n",
      "Epoch 43: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 87ms/step - loss: 0.1604 - accuracy: 0.9555 - val_loss: 0.4131 - val_accuracy: 0.9151 - lr: 6.2500e-04\n",
      "Epoch 44/100\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.9567Restoring model weights from the end of the best epoch: 24.\n",
      "\n",
      "Epoch 44: val_accuracy did not improve from 0.92336\n",
      "137/137 [==============================] - 12s 88ms/step - loss: 0.1588 - accuracy: 0.9567 - val_loss: 0.4027 - val_accuracy: 0.9161 - lr: 6.2500e-04\n",
      "Epoch 44: early stopping\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t30_150M_UR50D_unified_640_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "def build_model(input_shape):\n",
    "    input = Input(input_shape)\n",
    "    x = Conv1D(64, 5, strides=1, padding='same')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = MaxPooling1D(2, padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv1D(128, 5, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = MaxPooling1D(2, padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lr = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10\n",
    "    lr = initial_lr * np.power(drop, np.floor((1 + epoch) / epochs_drop))\n",
    "    return lr\n",
    "\n",
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "    input_shape = (640, 1)\n",
    "    model = build_model(input_shape)\n",
    "    \n",
    "    # Optimizer\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "    early_stop = EarlyStopping(monitor='val_accuracy', patience=20, verbose=1, restore_best_weights=True)\n",
    "    mc = ModelCheckpoint('best_model_640.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "    callbacks_list = [lrate, early_stop, mc]\n",
    "    \n",
    "    class_weight = {0: 1, 1: 2}  # Adjust the weights as needed\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, callbacks=callbacks_list, batch_size=32, class_weight=class_weight)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Load the best model\n",
    "saved_model = load_model('best_model_640.h5')\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_probas):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_probas > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        \n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5141fb51-a6ef-4f76-91b2-ac2fb5a3d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 15ms/step\n",
      "\n",
      "Optimized Test Dataset Results:\n",
      "Accuracy (ACC): 0.9233576642335767\n",
      "Balanced Accuracy (BACC): 0.8797910326995128\n",
      "Sensitivity (Sn): 0.7913669064748201\n",
      "Specificity (Sp): 0.9682151589242054\n",
      "MCC: 0.7921304996385995\n",
      "AUC: 0.8797910326995128\n",
      "True Positives (TP): 220\n",
      "False Positives (FP): 26\n",
      "True Negatives (TN): 792\n",
      "False Negatives (FN): 58\n",
      "Total Positive: 278\n",
      "Total Negative: 818\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test dataset\n",
    "predicted_probas_test = saved_model.predict(X_test, batch_size=32)\n",
    "best_threshold_test, best_mcc_test = optimize_threshold(y_test, predicted_probas_test)\n",
    "predicted_classes_test = (predicted_probas_test > best_threshold_test).astype(int)\n",
    "\n",
    "# Calculate metrics for the test dataset with optimized threshold\n",
    "accuracy_test = accuracy_score(y_test, predicted_classes_test)\n",
    "sensitivity_test = recall_score(y_test, predicted_classes_test)  # Sensitivity (Recall)\n",
    "TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, predicted_classes_test).ravel()\n",
    "specificity_test = TN_test / (TN_test + FP_test)  # Corrected Specificity calculation\n",
    "MCC_test = matthews_corrcoef(y_test, predicted_classes_test)\n",
    "auc_test = roc_auc_score(y_test, predicted_classes_test)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "# Print the adjusted results for the test dataset\n",
    "print(\"\\nOptimized Test Dataset Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "print(f\"Specificity (Sp): {specificity_test}\")\n",
    "print(f\"MCC: {MCC_test}\")\n",
    "print(f\"AUC: {auc_test}\")\n",
    "print(f\"True Positives (TP): {TP_test}\")\n",
    "print(f\"False Positives (FP): {FP_test}\")\n",
    "print(f\"True Negatives (TN): {TN_test}\")\n",
    "print(f\"False Negatives (FN): {FN_test}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive = np.sum(y_test)\n",
    "total_negative = len(y_test) - total_positive\n",
    "print(f\"Total Positive: {total_positive}\")\n",
    "print(f\"Total Negative: {total_negative}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
