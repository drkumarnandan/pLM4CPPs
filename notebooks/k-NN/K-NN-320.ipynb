{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda97fda-9c10-44b4-94be-baff549a43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the k-NN classifier with GridSearch for hyperparameter tuning\n",
    "def train_knn(X_train, y_train):\n",
    "    # Hyperparameter tuning using GridSearchCV\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "    }\n",
    "    knn = KNeighborsClassifier()\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model from GridSearchCV\n",
    "    best_knn = grid_search.best_estimator_\n",
    "    return best_knn\n",
    "\n",
    "# Train the k-NN model\n",
    "best_knn_model = train_knn(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predicted_classes_test = best_knn_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for the test dataset\n",
    "accuracy_test = accuracy_score(y_test, predicted_classes_test)\n",
    "sensitivity_test = recall_score(y_test, predicted_classes_test)  # Sensitivity (Recall)\n",
    "TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, predicted_classes_test).ravel()\n",
    "specificity_test = TN_test / (TN_test + FP_test)  # Corrected Specificity calculation\n",
    "MCC_test = matthews_corrcoef(y_test, predicted_classes_test)\n",
    "auc_test = roc_auc_score(y_test, predicted_classes_test)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b9b491-c4f2-4fae-bc13-417b1ac5ff22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Test Dataset Results (k-NN):\n",
      "Accuracy (ACC): 0.926094890510949\n",
      "Balanced Accuracy (BACC): 0.886374030360064\n",
      "Sensitivity (Sn): 0.8057553956834532\n",
      "Specificity (Sp): 0.9669926650366748\n",
      "MCC: 0.8001506427101813\n",
      "AUC: 0.8863740303600639\n",
      "True Positives (TP): 224\n",
      "False Positives (FP): 27\n",
      "True Negatives (TN): 791\n",
      "False Negatives (FN): 54\n",
      "Total Positive: 278\n",
      "Total Negative: 818\n"
     ]
    }
   ],
   "source": [
    "# Print the adjusted results for the test dataset\n",
    "print(\"\\nOptimized Test Dataset Results (k-NN):\")\n",
    "print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "print(f\"Specificity (Sp): {specificity_test}\")\n",
    "print(f\"MCC: {MCC_test}\")\n",
    "print(f\"AUC: {auc_test}\")\n",
    "print(f\"True Positives (TP): {TP_test}\")\n",
    "print(f\"False Positives (FP): {FP_test}\")\n",
    "print(f\"True Negatives (TN): {TN_test}\")\n",
    "print(f\"False Negatives (FN): {FN_test}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive = np.sum(y_test)\n",
    "total_negative = len(y_test) - total_positive\n",
    "print(f\"Total Positive: {total_positive}\")\n",
    "print(f\"Total Negative: {total_negative}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50260e56-d5e1-4d5e-8753-3ad9cef8e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized External Dataset (KELM) Results (k-NN):\n",
      "Accuracy (ACC): 0.8125\n",
      "Balanced Accuracy (BACC): 0.8125\n",
      "Sensitivity (Sn): 0.625\n",
      "Specificity (Sp): 1.0\n",
      "MCC: 0.6741998624632421\n",
      "AUC: 0.8125\n",
      "True Positives (TP): 60\n",
      "False Positives (FP): 0\n",
      "True Negatives (TN): 96\n",
      "False Negatives (FN): 36\n",
      "Total Positive: 96\n",
      "Total Negative: 96\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the external dataset (KELM)\n",
    "dataset_external = pd.read_csv('kelm_dataset.csv', na_filter=False)\n",
    "X_external_data_name = 'kelm_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_external_data = pd.read_csv(X_external_data_name, header=0, index_col=0, delimiter=',')\n",
    "X_external = np.array(X_external_data)\n",
    "y_external = np.array(dataset_external['label'])\n",
    "\n",
    "# Normalize the external dataset\n",
    "X_external_normalized = scaler.transform(X_external)\n",
    "\n",
    "# Predict for the external dataset\n",
    "predicted_classes_ext = best_knn_model.predict(X_external_normalized)\n",
    "\n",
    "# Calculate metrics for the external dataset\n",
    "accuracy_ext = accuracy_score(y_external, predicted_classes_ext)\n",
    "sensitivity_ext = recall_score(y_external, predicted_classes_ext)  # Sensitivity (Recall)\n",
    "TN_ext, FP_ext, FN_ext, TP_ext = confusion_matrix(y_external, predicted_classes_ext).ravel()\n",
    "specificity_ext = TN_ext / (TN_ext + FP_ext)  # Corrected Specificity calculation\n",
    "MCC_ext = matthews_corrcoef(y_external, predicted_classes_ext)\n",
    "auc_ext = roc_auc_score(y_external, predicted_classes_ext)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_ext = (sensitivity_ext + specificity_ext) / 2\n",
    "\n",
    "# Print the adjusted results for the external dataset\n",
    "print(\"\\nOptimized External Dataset (KELM) Results (k-NN):\")\n",
    "print(f\"Accuracy (ACC): {accuracy_ext}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_ext}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_ext}\")\n",
    "print(f\"Specificity (Sp): {specificity_ext}\")\n",
    "print(f\"MCC: {MCC_ext}\")\n",
    "print(f\"AUC: {auc_ext}\")\n",
    "print(f\"True Positives (TP): {TP_ext}\")\n",
    "print(f\"False Positives (FP): {FP_ext}\")\n",
    "print(f\"True Negatives (TN): {TN_ext}\")\n",
    "print(f\"False Negatives (FN): {FN_ext}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive_ext = np.sum(y_external)\n",
    "total_negative_ext = len(y_external) - total_positive_ext\n",
    "print(f\"Total Positive: {total_positive_ext}\")\n",
    "print(f\"Total Negative: {total_negative_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d030fa0a-b461-4367-932a-24d7a70dc8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "\n",
      "Test Dataset Results:\n",
      "Accuracy (ACC): 0.9306569343065694\n",
      "Balanced Accuracy (BACC): 0.8965541503227735\n",
      "Sensitivity (Sn): 0.8273381294964028\n",
      "Specificity (Sp): 0.9657701711491442\n",
      "MCC: 0.8133915993157494\n",
      "AUC: 0.8965541503227735\n",
      "Best Threshold: 0.45000000000000007\n",
      "\n",
      "External Dataset Results:\n",
      "Accuracy (ACC): 0.859375\n",
      "Balanced Accuracy (BACC): 0.859375\n",
      "Sensitivity (Sn): 0.7604166666666666\n",
      "Specificity (Sp): 0.9583333333333334\n",
      "MCC: 0.7332546199393071\n",
      "AUC: 0.8593749999999999\n",
      "Best Threshold: 0.20000000000000004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Function to optimize the number of neighbors (k)\n",
    "def optimize_k(X_train, y_train):\n",
    "    param_grid = {'n_neighbors': range(1, 21), 'weights': ['uniform', 'distance']}\n",
    "    knn = KNeighborsClassifier()\n",
    "    grid_search = GridSearchCV(knn, param_grid, scoring='accuracy', cv=5, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_params_\n",
    "\n",
    "# Train the k-NN model\n",
    "def train_knn(X_train, y_train, X_test, y_test):\n",
    "    # Optimize k and weights\n",
    "    best_params = optimize_k(X_train, y_train)\n",
    "    k = best_params['n_neighbors']\n",
    "    weights = best_params['weights']\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights=weights)\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn, k, weights\n",
    "\n",
    "# Evaluate the model with optimized threshold\n",
    "def evaluate_model(knn, X_test, y_test):\n",
    "    predicted_probas = knn.predict_proba(X_test)[:, 1]\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (predicted_probas > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    y_pred_final = (predicted_probas > best_threshold).astype(int)\n",
    "    accuracy = accuracy_score(y_test, y_pred_final)\n",
    "    sensitivity = recall_score(y_test, y_pred_final)\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, y_pred_final).ravel()\n",
    "    specificity = TN / (TN + FP)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred_final)\n",
    "    auc = roc_auc_score(y_test, y_pred_final)\n",
    "    balanced_accuracy = (sensitivity + specificity) / 2\n",
    "\n",
    "    return accuracy, balanced_accuracy, sensitivity, specificity, mcc, auc, best_threshold\n",
    "\n",
    "# Train the model\n",
    "knn_model, best_k, best_weights = train_knn(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate on test dataset\n",
    "acc_test, bacc_test, sn_test, sp_test, mcc_test, auc_test, best_threshold_test = evaluate_model(knn_model, X_test, y_test)\n",
    "\n",
    "# Print results for test dataset\n",
    "print(\"\\nTest Dataset Results:\")\n",
    "print(f\"Accuracy (ACC): {acc_test}\")\n",
    "print(f\"Balanced Accuracy (BACC): {bacc_test}\")\n",
    "print(f\"Sensitivity (Sn): {sn_test}\")\n",
    "print(f\"Specificity (Sp): {sp_test}\")\n",
    "print(f\"MCC: {mcc_test}\")\n",
    "print(f\"AUC: {auc_test}\")\n",
    "print(f\"Best Threshold: {best_threshold_test}\")\n",
    "\n",
    "# Load and normalize external dataset\n",
    "dataset_external = pd.read_csv('kelm_dataset.csv', na_filter=False)\n",
    "X_external_data_name = 'kelm_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_external_data = pd.read_csv(X_external_data_name, header=0, index_col=0, delimiter=',')\n",
    "X_external = np.array(X_external_data)\n",
    "y_external = np.array(dataset_external['label'])\n",
    "\n",
    "X_external_normalized = scaler.transform(X_external)\n",
    "\n",
    "# Evaluate on external dataset\n",
    "acc_ext, bacc_ext, sn_ext, sp_ext, mcc_ext, auc_ext, best_threshold_ext = evaluate_model(knn_model, X_external_normalized, y_external)\n",
    "\n",
    "# Print results for external dataset\n",
    "print(\"\\nExternal Dataset Results:\")\n",
    "print(f\"Accuracy (ACC): {acc_ext}\")\n",
    "print(f\"Balanced Accuracy (BACC): {bacc_ext}\")\n",
    "print(f\"Sensitivity (Sn): {sn_ext}\")\n",
    "print(f\"Specificity (Sp): {sp_ext}\")\n",
    "print(f\"MCC: {mcc_ext}\")\n",
    "print(f\"AUC: {auc_ext}\")\n",
    "print(f\"Best Threshold: {best_threshold_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7424751-eb14-4e20-8943-d7b44f69aec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Test Dataset Results:\n",
      "Accuracy (ACC): 0.926094890510949\n",
      "Balanced Accuracy (BACC): 0.886374030360064\n",
      "Sensitivity (Sn): 0.8057553956834532\n",
      "Specificity (Sp): 0.9669926650366748\n",
      "MCC: 0.8001506427101813\n",
      "AUC: 0.9514432463808904\n",
      "True Positives (TP): 224\n",
      "False Positives (FP): 27\n",
      "True Negatives (TN): 791\n",
      "False Negatives (FN): 54\n",
      "\n",
      "Optimized External Dataset (KELM) Results:\n",
      "Accuracy (ACC): 0.8385416666666666\n",
      "Balanced Accuracy (BACC): 0.8385416666666666\n",
      "Sensitivity (Sn): 0.6979166666666666\n",
      "Specificity (Sp): 0.9791666666666666\n",
      "MCC: 0.7055637431113225\n",
      "AUC: 0.8685438368055556\n",
      "True Positives (TP): 67\n",
      "False Positives (FP): 2\n",
      "True Negatives (TN): 94\n",
      "False Negatives (FN): 29\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build and train k-NN model\n",
    "def train_knn(X_train, y_train, n_neighbors=5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn\n",
    "\n",
    "# Train the k-NN model\n",
    "knn_model = train_knn(X_train, y_train)\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_probas):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_probas >= threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_mcc\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "predicted_probas_test = knn_model.predict_proba(X_test)[:, 1]\n",
    "best_threshold_test, best_mcc_test = optimize_threshold(y_test, predicted_probas_test)\n",
    "predicted_classes_test = (predicted_probas_test >= best_threshold_test).astype(int)\n",
    "\n",
    "# Calculate metrics for the test dataset with optimized threshold\n",
    "accuracy_test = accuracy_score(y_test, predicted_classes_test)\n",
    "sensitivity_test = recall_score(y_test, predicted_classes_test)  # Sensitivity (Recall)\n",
    "TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, predicted_classes_test).ravel()\n",
    "specificity_test = TN_test / (TN_test + FP_test)\n",
    "MCC_test = matthews_corrcoef(y_test, predicted_classes_test)\n",
    "auc_test = roc_auc_score(y_test, predicted_probas_test)\n",
    "\n",
    "# Compute the balanced accuracy\n",
    "balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "# Print the adjusted results for the test dataset\n",
    "print(\"\\nOptimized Test Dataset Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "print(f\"Specificity (Sp): {specificity_test}\")\n",
    "print(f\"MCC: {MCC_test}\")\n",
    "print(f\"AUC: {auc_test}\")\n",
    "print(f\"True Positives (TP): {TP_test}\")\n",
    "print(f\"False Positives (FP): {FP_test}\")\n",
    "print(f\"True Negatives (TN): {TN_test}\")\n",
    "print(f\"False Negatives (FN): {FN_test}\")\n",
    "\n",
    "# Evaluate on the external dataset (KELM)\n",
    "dataset_external = pd.read_csv('kelm_dataset.csv', na_filter=False)\n",
    "X_external_data_name = 'kelm_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_external_data = pd.read_csv(X_external_data_name, header=0, index_col=0, delimiter=',')\n",
    "X_external = np.array(X_external_data)\n",
    "y_external = np.array(dataset_external['label'])\n",
    "\n",
    "# Normalize the external dataset\n",
    "X_external_normalized = scaler.transform(X_external)\n",
    "\n",
    "# Predict probabilities for the external dataset\n",
    "predicted_probas_ext = knn_model.predict_proba(X_external_normalized)[:, 1]\n",
    "best_threshold_ext, best_mcc_ext = optimize_threshold(y_external, predicted_probas_ext)\n",
    "predicted_classes_ext = (predicted_probas_ext >= best_threshold_ext).astype(int)\n",
    "\n",
    "# Calculate metrics for the external dataset with optimized threshold\n",
    "accuracy_ext = accuracy_score(y_external, predicted_classes_ext)\n",
    "sensitivity_ext = recall_score(y_external, predicted_classes_ext)\n",
    "TN_ext, FP_ext, FN_ext, TP_ext = confusion_matrix(y_external, predicted_classes_ext).ravel()\n",
    "specificity_ext = TN_ext / (TN_ext + FP_ext)\n",
    "MCC_ext = matthews_corrcoef(y_external, predicted_classes_ext)\n",
    "auc_ext = roc_auc_score(y_external, predicted_probas_ext)\n",
    "\n",
    "# Compute the balanced accuracy\n",
    "balanced_accuracy_ext = (sensitivity_ext + specificity_ext) / 2\n",
    "\n",
    "# Print the adjusted results for the external dataset\n",
    "print(\"\\nOptimized External Dataset (KELM) Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_ext}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_ext}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_ext}\")\n",
    "print(f\"Specificity (Sp): {specificity_ext}\")\n",
    "print(f\"MCC: {MCC_ext}\")\n",
    "print(f\"AUC: {auc_ext}\")\n",
    "print(f\"True Positives (TP): {TP_ext}\")\n",
    "print(f\"False Positives (FP): {FP_ext}\")\n",
    "print(f\"True Negatives (TN): {TN_ext}\")\n",
    "print(f\"False Negatives (FN): {FN_ext}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f117ae8-4a2c-4beb-986e-6808efab7996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
