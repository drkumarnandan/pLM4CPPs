{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b6e1a38-e285-49c5-b031-e26f47e01e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Test Dataset Results:\n",
      "Accuracy (ACC): 0.9124087591240876\n",
      "Balanced Accuracy (BACC): 0.8985769819352343\n",
      "Sensitivity (Sn): 0.8705035971223022\n",
      "Specificity (Sp): 0.9266503667481663\n",
      "MCC: 0.7762963372838538\n",
      "AUC: 0.9525514063077167\n",
      "True Positives (TP): 242\n",
      "False Positives (FP): 60\n",
      "True Negatives (TN): 758\n",
      "False Negatives (FN): 36\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Test Dataset Results:\n",
      "Accuracy (ACC): 0.9151459854014599\n",
      "Balanced Accuracy (BACC): 0.867165924961742\n",
      "Sensitivity (Sn): 0.7697841726618705\n",
      "Specificity (Sp): 0.9645476772616137\n",
      "MCC: 0.7691548139588161\n",
      "AUC: 0.952718509788746\n",
      "True Positives (TP): 214\n",
      "False Positives (FP): 29\n",
      "True Negatives (TN): 789\n",
      "False Negatives (FN): 64\n",
      "\n",
      "Training Support Vector Machine...\n",
      "\n",
      "Support Vector Machine Test Dataset Results:\n",
      "Accuracy (ACC): 0.916970802919708\n",
      "Balanced Accuracy (BACC): 0.8588899051907618\n",
      "Sensitivity (Sn): 0.7410071942446043\n",
      "Specificity (Sp): 0.9767726161369193\n",
      "MCC: 0.7731966284852645\n",
      "AUC: 0.9556780003869765\n",
      "True Positives (TP): 206\n",
      "False Positives (FP): 19\n",
      "True Negatives (TN): 799\n",
      "False Negatives (FN): 72\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "\n",
      "K-Nearest Neighbors Test Dataset Results:\n",
      "Accuracy (ACC): 0.9197080291970803\n",
      "Balanced Accuracy (BACC): 0.8714094738878824\n",
      "Sensitivity (Sn): 0.7733812949640287\n",
      "Specificity (Sp): 0.969437652811736\n",
      "MCC: 0.7815189619833018\n",
      "AUC: 0.9463311990994001\n",
      "True Positives (TP): 215\n",
      "False Positives (FP): 25\n",
      "True Negatives (TN): 793\n",
      "False Negatives (FN): 63\n",
      "\n",
      "Training Multilayer Perceptron...\n",
      "\n",
      "Multilayer Perceptron Test Dataset Results:\n",
      "Accuracy (ACC): 0.9105839416058394\n",
      "Balanced Accuracy (BACC): 0.8926052312184483\n",
      "Sensitivity (Sn): 0.8561151079136691\n",
      "Specificity (Sp): 0.9290953545232273\n",
      "MCC: 0.7694745820923523\n",
      "AUC: 0.9517246838226241\n",
      "True Positives (TP): 238\n",
      "False Positives (FP): 58\n",
      "True Negatives (TN): 760\n",
      "False Negatives (FN): 40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'seqvev_whole_smaple_reduced_embeddings_file_ordered.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# List of classifiers with default parameters\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Multilayer Perceptron': MLPClassifier()\n",
    "}\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_scores):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_scores > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_mcc\n",
    "\n",
    "# Evaluate each classifier\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining {clf_name}...\")\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get predicted probabilities or decision scores\n",
    "    if clf_name == 'Support Vector Machine':\n",
    "        # Use decision_function for SVC as probability=True is not default\n",
    "        y_pred_scores_test = clf.decision_function(X_test)\n",
    "    else:\n",
    "        # Use predict_proba for classifiers that support it\n",
    "        y_pred_scores_test = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Optimize the threshold based on MCC\n",
    "    best_threshold_test, best_mcc_test = optimize_threshold(y_test, y_pred_scores_test)\n",
    "    y_pred_test = (y_pred_scores_test > best_threshold_test).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    sensitivity_test = recall_score(y_test, y_pred_test)  # Sensitivity (Recall)\n",
    "    TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "    specificity_test = TN_test / (TN_test + FP_test)\n",
    "    MCC_test = matthews_corrcoef(y_test, y_pred_test)\n",
    "\n",
    "    # Compute AUC\n",
    "    if clf_name == 'Support Vector Machine':\n",
    "        auc_test = roc_auc_score(y_test, y_pred_scores_test)  # Use decision_function scores\n",
    "    else:\n",
    "        auc_test = roc_auc_score(y_test, y_pred_scores_test)\n",
    "\n",
    "    # Compute the correct balanced accuracy\n",
    "    balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n{clf_name} Test Dataset Results:\")\n",
    "    print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "    print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "    print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "    print(f\"Specificity (Sp): {specificity_test}\")\n",
    "    print(f\"MCC: {MCC_test}\")\n",
    "    print(f\"AUC: {auc_test}\")\n",
    "    print(f\"True Positives (TP): {TP_test}\")\n",
    "    print(f\"False Positives (FP): {FP_test}\")\n",
    "    print(f\"True Negatives (TN): {TN_test}\")\n",
    "    print(f\"False Negatives (FN): {FN_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec48e22-1b63-4eaa-91cb-04a964f5d9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:36:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Test Dataset Results:\n",
      "Accuracy (ACC): 0.916970802919708\n",
      "Balanced Accuracy (BACC): 0.8873854461662943\n",
      "Sensitivity (Sn): 0.8273381294964028\n",
      "Specificity (Sp): 0.9474327628361858\n",
      "MCC: 0.7794551033164274\n",
      "AUC: 0.9574809589980827\n",
      "True Positives (TP): 230\n",
      "False Positives (FP): 43\n",
      "True Negatives (TN): 775\n",
      "False Negatives (FN): 48\n",
      "Total Positive: 278\n",
      "Total Negative: 818\n",
      "\n",
      "Optimized External Dataset (KELM) Results:\n",
      "Accuracy (ACC): 0.828125\n",
      "Balanced Accuracy (BACC): 0.828125\n",
      "Sensitivity (Sn): 0.6875\n",
      "Specificity (Sp): 0.96875\n",
      "MCC: 0.683854089477128\n",
      "AUC: 0.8985460069444444\n",
      "True Positives (TP): 66\n",
      "False Positives (FP): 3\n",
      "True Negatives (TN): 93\n",
      "False Negatives (FN): 30\n",
      "Total Positive: 96\n",
      "Total Negative: 96\n"
     ]
    }
   ],
   "source": [
    "#uses default parameters\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'seqvev_whole_smaple_reduced_embeddings_file_ordered.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the XGBoost classifier with default parameters\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_probas):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_probas > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        \n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_mcc\n",
    "\n",
    "# Predict probabilities for the test dataset\n",
    "predicted_probas_test = xgb_model.predict_proba(X_test)[:, 1]\n",
    "best_threshold_test, best_mcc_test = optimize_threshold(y_test, predicted_probas_test)\n",
    "predicted_classes_test = (predicted_probas_test > best_threshold_test).astype(int)\n",
    "\n",
    "# Calculate metrics for the test dataset with optimized threshold\n",
    "accuracy_test = accuracy_score(y_test, predicted_classes_test)\n",
    "sensitivity_test = recall_score(y_test, predicted_classes_test)  # Sensitivity (Recall)\n",
    "TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, predicted_classes_test).ravel()\n",
    "specificity_test = TN_test / (TN_test + FP_test)  # Corrected Specificity calculation\n",
    "MCC_test = matthews_corrcoef(y_test, predicted_classes_test)\n",
    "auc_test = roc_auc_score(y_test, predicted_probas_test)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "# Print the adjusted results for the test dataset\n",
    "print(\"\\nOptimized Test Dataset Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "print(f\"Specificity (Sp): {specificity_test}\")\n",
    "print(f\"MCC: {MCC_test}\")\n",
    "print(f\"AUC: {auc_test}\")\n",
    "print(f\"True Positives (TP): {TP_test}\")\n",
    "print(f\"False Positives (FP): {FP_test}\")\n",
    "print(f\"True Negatives (TN): {TN_test}\")\n",
    "print(f\"False Negatives (FN): {FN_test}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive = np.sum(y_test)\n",
    "total_negative = len(y_test) - total_positive\n",
    "print(f\"Total Positive: {total_positive}\")\n",
    "print(f\"Total Negative: {total_negative}\")\n",
    "\n",
    "# Evaluate on the external dataset (KELM)\n",
    "dataset_external = pd.read_csv('kelm_dataset.csv', na_filter=False)\n",
    "X_external_data_name = 'seqvev_kelm_data_reduced_embeddings_file_ordered.csv'\n",
    "X_external_data = pd.read_csv(X_external_data_name, header=0, index_col=0, delimiter=',')\n",
    "X_external = np.array(X_external_data)\n",
    "y_external = np.array(dataset_external['label'])\n",
    "\n",
    "# Normalize the external dataset\n",
    "X_external_normalized = scaler.transform(X_external)\n",
    "\n",
    "# Predict probabilities for external dataset\n",
    "predicted_probas_ext = xgb_model.predict_proba(X_external_normalized)[:, 1]\n",
    "best_threshold_ext, best_mcc_ext = optimize_threshold(y_external, predicted_probas_ext)\n",
    "predicted_classes_ext = (predicted_probas_ext > best_threshold_ext).astype(int)\n",
    "\n",
    "# Calculate metrics for the external dataset with optimized threshold\n",
    "accuracy_ext = accuracy_score(y_external, predicted_classes_ext)\n",
    "sensitivity_ext = recall_score(y_external, predicted_classes_ext)  # Sensitivity (Recall)\n",
    "TN_ext, FP_ext, FN_ext, TP_ext = confusion_matrix(y_external, predicted_classes_ext).ravel()\n",
    "specificity_ext = TN_ext / (TN_ext + FP_ext)  # Corrected Specificity calculation\n",
    "MCC_ext = matthews_corrcoef(y_external, predicted_classes_ext)\n",
    "auc_ext = roc_auc_score(y_external, predicted_probas_ext)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_ext = (sensitivity_ext + specificity_ext) / 2\n",
    "\n",
    "# Print the adjusted results for the external dataset\n",
    "print(\"\\nOptimized External Dataset (KELM) Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_ext}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_ext}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_ext}\")\n",
    "print(f\"Specificity (Sp): {specificity_ext}\")\n",
    "print(f\"MCC: {MCC_ext}\")\n",
    "print(f\"AUC: {auc_ext}\")\n",
    "print(f\"True Positives (TP): {TP_ext}\")\n",
    "print(f\"False Positives (FP): {FP_ext}\")\n",
    "print(f\"True Negatives (TN): {TN_ext}\")\n",
    "print(f\"False Negatives (FN): {FN_ext}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive_ext = np.sum(y_external)\n",
    "total_negative_ext = len(y_external) - total_positive_ext\n",
    "print(f\"Total Positive: {total_positive_ext}\")\n",
    "print(f\"Total Negative: {total_negative_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14a481-8345-4225-b852-fdd171536486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
