{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70254bc3-77fa-4cdd-b488-dfef636668da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Test Dataset Results:\n",
      "Accuracy (ACC): 0.9078467153284672\n",
      "Balanced Accuracy (BACC): 0.861088635204306\n",
      "Sensitivity (Sn): 0.7661870503597122\n",
      "Specificity (Sp): 0.9559902200488998\n",
      "MCC: 0.7498967761258897\n",
      "AUC: 0.9487739881444478\n",
      "True Positives (TP): 213\n",
      "False Positives (FP): 36\n",
      "True Negatives (TN): 782\n",
      "False Negatives (FN): 65\n",
      "\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Test Dataset Results:\n",
      "Accuracy (ACC): 0.9142335766423357\n",
      "Balanced Accuracy (BACC): 0.8760531916764877\n",
      "Sensitivity (Sn): 0.7985611510791367\n",
      "Specificity (Sp): 0.9535452322738386\n",
      "MCC: 0.7692872095711956\n",
      "AUC: 0.9483100561115899\n",
      "True Positives (TP): 222\n",
      "False Positives (FP): 38\n",
      "True Negatives (TN): 780\n",
      "False Negatives (FN): 56\n",
      "\n",
      "Training Support Vector Machine...\n",
      "\n",
      "Support Vector Machine Test Dataset Results:\n",
      "Accuracy (ACC): 0.9124087591240876\n",
      "Balanced Accuracy (BACC): 0.8522717278499938\n",
      "Sensitivity (Sn): 0.7302158273381295\n",
      "Specificity (Sp): 0.9743276283618582\n",
      "MCC: 0.7601942553298378\n",
      "AUC: 0.9523491231464707\n",
      "True Positives (TP): 203\n",
      "False Positives (FP): 21\n",
      "True Negatives (TN): 797\n",
      "False Negatives (FN): 75\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "\n",
      "K-Nearest Neighbors Test Dataset Results:\n",
      "Accuracy (ACC): 0.9124087591240876\n",
      "Balanced Accuracy (BACC): 0.8605829273011908\n",
      "Sensitivity (Sn): 0.7553956834532374\n",
      "Specificity (Sp): 0.9657701711491442\n",
      "MCC: 0.7610305362391587\n",
      "AUC: 0.9407508223250249\n",
      "True Positives (TP): 210\n",
      "False Positives (FP): 28\n",
      "True Negatives (TN): 790\n",
      "False Negatives (FN): 68\n",
      "\n",
      "Training Multilayer Perceptron...\n",
      "\n",
      "Multilayer Perceptron Test Dataset Results:\n",
      "Accuracy (ACC): 0.9197080291970803\n",
      "Balanced Accuracy (BACC): 0.8856572443756486\n",
      "Sensitivity (Sn): 0.8165467625899281\n",
      "Specificity (Sp): 0.9547677261613692\n",
      "MCC: 0.7848143090127281\n",
      "AUC: 0.9548029058415859\n",
      "True Positives (TP): 227\n",
      "False Positives (FP): 37\n",
      "True Negatives (TN): 781\n",
      "False Negatives (FN): 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t30_150M_UR50D_unified_640_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# List of classifiers with default parameters\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Multilayer Perceptron': MLPClassifier()\n",
    "}\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_scores):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_scores > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_mcc\n",
    "\n",
    "# Evaluate each classifier\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining {clf_name}...\")\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get predicted probabilities or decision scores\n",
    "    if clf_name == 'Support Vector Machine':\n",
    "        # Use decision_function for SVC as probability=True is not default\n",
    "        y_pred_scores_test = clf.decision_function(X_test)\n",
    "    else:\n",
    "        # Use predict_proba for classifiers that support it\n",
    "        y_pred_scores_test = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Optimize the threshold based on MCC\n",
    "    best_threshold_test, best_mcc_test = optimize_threshold(y_test, y_pred_scores_test)\n",
    "    y_pred_test = (y_pred_scores_test > best_threshold_test).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    sensitivity_test = recall_score(y_test, y_pred_test)  # Sensitivity (Recall)\n",
    "    TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "    specificity_test = TN_test / (TN_test + FP_test)\n",
    "    MCC_test = matthews_corrcoef(y_test, y_pred_test)\n",
    "\n",
    "    # Compute AUC\n",
    "    if clf_name == 'Support Vector Machine':\n",
    "        auc_test = roc_auc_score(y_test, y_pred_scores_test)  # Use decision_function scores\n",
    "    else:\n",
    "        auc_test = roc_auc_score(y_test, y_pred_scores_test)\n",
    "\n",
    "    # Compute the correct balanced accuracy\n",
    "    balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n{clf_name} Test Dataset Results:\")\n",
    "    print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "    print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "    print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "    print(f\"Specificity (Sp): {specificity_test}\")\n",
    "    print(f\"MCC: {MCC_test}\")\n",
    "    print(f\"AUC: {auc_test}\")\n",
    "    print(f\"True Positives (TP): {TP_test}\")\n",
    "    print(f\"False Positives (FP): {FP_test}\")\n",
    "    print(f\"True Negatives (TN): {TN_test}\")\n",
    "    print(f\"False Negatives (FN): {FN_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f60f8849-98ad-4dbc-a852-7c5469af23db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:19:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Test Dataset Results:\n",
      "Accuracy (ACC): 0.9233576642335767\n",
      "Balanced Accuracy (BACC): 0.8797910326995128\n",
      "Sensitivity (Sn): 0.7913669064748201\n",
      "Specificity (Sp): 0.9682151589242054\n",
      "MCC: 0.7921304996385995\n",
      "AUC: 0.9594686109303266\n",
      "True Positives (TP): 220\n",
      "False Positives (FP): 26\n",
      "True Negatives (TN): 792\n",
      "False Negatives (FN): 58\n",
      "Total Positive: 278\n",
      "Total Negative: 818\n",
      "\n",
      "Optimized External Dataset (KELM) Results:\n",
      "Accuracy (ACC): 0.8541666666666666\n",
      "Balanced Accuracy (BACC): 0.8541666666666667\n",
      "Sensitivity (Sn): 0.7395833333333334\n",
      "Specificity (Sp): 0.96875\n",
      "MCC: 0.7276994542035816\n",
      "AUC: 0.9084201388888891\n",
      "True Positives (TP): 71\n",
      "False Positives (FP): 3\n",
      "True Negatives (TN): 93\n",
      "False Negatives (FN): 25\n",
      "Total Positive: 96\n",
      "Total Negative: 96\n"
     ]
    }
   ],
   "source": [
    "#uses default parameters\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t30_150M_UR50D_unified_640_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the XGBoost classifier with default parameters\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_probas):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_probas > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        \n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_mcc\n",
    "\n",
    "# Predict probabilities for the test dataset\n",
    "predicted_probas_test = xgb_model.predict_proba(X_test)[:, 1]\n",
    "best_threshold_test, best_mcc_test = optimize_threshold(y_test, predicted_probas_test)\n",
    "predicted_classes_test = (predicted_probas_test > best_threshold_test).astype(int)\n",
    "\n",
    "# Calculate metrics for the test dataset with optimized threshold\n",
    "accuracy_test = accuracy_score(y_test, predicted_classes_test)\n",
    "sensitivity_test = recall_score(y_test, predicted_classes_test)  # Sensitivity (Recall)\n",
    "TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, predicted_classes_test).ravel()\n",
    "specificity_test = TN_test / (TN_test + FP_test)  # Corrected Specificity calculation\n",
    "MCC_test = matthews_corrcoef(y_test, predicted_classes_test)\n",
    "auc_test = roc_auc_score(y_test, predicted_probas_test)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "# Print the adjusted results for the test dataset\n",
    "print(\"\\nOptimized Test Dataset Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "print(f\"Specificity (Sp): {specificity_test}\")\n",
    "print(f\"MCC: {MCC_test}\")\n",
    "print(f\"AUC: {auc_test}\")\n",
    "print(f\"True Positives (TP): {TP_test}\")\n",
    "print(f\"False Positives (FP): {FP_test}\")\n",
    "print(f\"True Negatives (TN): {TN_test}\")\n",
    "print(f\"False Negatives (FN): {FN_test}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive = np.sum(y_test)\n",
    "total_negative = len(y_test) - total_positive\n",
    "print(f\"Total Positive: {total_positive}\")\n",
    "print(f\"Total Negative: {total_negative}\")\n",
    "\n",
    "# Evaluate on the external dataset (KELM)\n",
    "dataset_external = pd.read_csv('kelm_dataset.csv', na_filter=False)\n",
    "X_external_data_name = 'kelm_dataset_esm2_t30_150M_UR50D_unified_640_dimension.csv'\n",
    "X_external_data = pd.read_csv(X_external_data_name, header=0, index_col=0, delimiter=',')\n",
    "X_external = np.array(X_external_data)\n",
    "y_external = np.array(dataset_external['label'])\n",
    "\n",
    "# Normalize the external dataset\n",
    "X_external_normalized = scaler.transform(X_external)\n",
    "\n",
    "# Predict probabilities for external dataset\n",
    "predicted_probas_ext = xgb_model.predict_proba(X_external_normalized)[:, 1]\n",
    "best_threshold_ext, best_mcc_ext = optimize_threshold(y_external, predicted_probas_ext)\n",
    "predicted_classes_ext = (predicted_probas_ext > best_threshold_ext).astype(int)\n",
    "\n",
    "# Calculate metrics for the external dataset with optimized threshold\n",
    "accuracy_ext = accuracy_score(y_external, predicted_classes_ext)\n",
    "sensitivity_ext = recall_score(y_external, predicted_classes_ext)  # Sensitivity (Recall)\n",
    "TN_ext, FP_ext, FN_ext, TP_ext = confusion_matrix(y_external, predicted_classes_ext).ravel()\n",
    "specificity_ext = TN_ext / (TN_ext + FP_ext)  # Corrected Specificity calculation\n",
    "MCC_ext = matthews_corrcoef(y_external, predicted_classes_ext)\n",
    "auc_ext = roc_auc_score(y_external, predicted_probas_ext)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_ext = (sensitivity_ext + specificity_ext) / 2\n",
    "\n",
    "# Print the adjusted results for the external dataset\n",
    "print(\"\\nOptimized External Dataset (KELM) Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_ext}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_ext}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_ext}\")\n",
    "print(f\"Specificity (Sp): {specificity_ext}\")\n",
    "print(f\"MCC: {MCC_ext}\")\n",
    "print(f\"AUC: {auc_ext}\")\n",
    "print(f\"True Positives (TP): {TP_ext}\")\n",
    "print(f\"False Positives (FP): {FP_ext}\")\n",
    "print(f\"True Negatives (TN): {TN_ext}\")\n",
    "print(f\"False Negatives (FN): {FN_ext}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive_ext = np.sum(y_external)\n",
    "total_negative_ext = len(y_external) - total_positive_ext\n",
    "print(f\"Total Positive: {total_positive_ext}\")\n",
    "print(f\"Total Negative: {total_negative_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489ee19-6a7b-4775-a980-04a6a05908b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
