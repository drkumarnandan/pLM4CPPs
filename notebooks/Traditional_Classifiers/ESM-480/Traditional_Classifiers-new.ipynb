{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2db0dff-6669-4496-a92e-190787a37278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Test Dataset Results:\n",
      "Accuracy (ACC): 0.9114963503649635\n",
      "Balanced Accuracy (BACC): 0.8789687076744472\n",
      "Sensitivity (Sn): 0.8129496402877698\n",
      "Specificity (Sp): 0.9449877750611247\n",
      "MCC: 0.7644001726812346\n",
      "AUC: 0.9469930168334769\n",
      "True Positives (TP): 226\n",
      "False Positives (FP): 45\n",
      "True Negatives (TN): 773\n",
      "False Negatives (FN): 52\n",
      "\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Test Dataset Results:\n",
      "Accuracy (ACC): 0.9142335766423357\n",
      "Balanced Accuracy (BACC): 0.8867390195423124\n",
      "Sensitivity (Sn): 0.8309352517985612\n",
      "Specificity (Sp): 0.9425427872860636\n",
      "MCC: 0.7734780390846248\n",
      "AUC: 0.9504802026349579\n",
      "True Positives (TP): 231\n",
      "False Positives (FP): 47\n",
      "True Negatives (TN): 771\n",
      "False Negatives (FN): 47\n",
      "\n",
      "Training Support Vector Machine...\n",
      "\n",
      "Support Vector Machine Test Dataset Results:\n",
      "Accuracy (ACC): 0.9096715328467153\n",
      "Balanced Accuracy (BACC): 0.8492506728113842\n",
      "Sensitivity (Sn): 0.7266187050359713\n",
      "Specificity (Sp): 0.9718826405867971\n",
      "MCC: 0.7524297529919032\n",
      "AUC: 0.9528548310495857\n",
      "True Positives (TP): 202\n",
      "False Positives (FP): 23\n",
      "True Negatives (TN): 795\n",
      "False Negatives (FN): 76\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "\n",
      "K-Nearest Neighbors Test Dataset Results:\n",
      "Accuracy (ACC): 0.9206204379562044\n",
      "Balanced Accuracy (BACC): 0.8791446060755308\n",
      "Sensitivity (Sn): 0.7949640287769785\n",
      "Specificity (Sp): 0.9633251833740831\n",
      "MCC: 0.7851790658619568\n",
      "AUC: 0.9395635081177112\n",
      "True Positives (TP): 221\n",
      "False Positives (FP): 30\n",
      "True Negatives (TN): 788\n",
      "False Negatives (FN): 57\n",
      "\n",
      "Training Multilayer Perceptron...\n",
      "\n",
      "Multilayer Perceptron Test Dataset Results:\n",
      "Accuracy (ACC): 0.906934306569343\n",
      "Balanced Accuracy (BACC): 0.8889729292360733\n",
      "Sensitivity (Sn): 0.8525179856115108\n",
      "Specificity (Sp): 0.9254278728606357\n",
      "MCC: 0.7607445420157273\n",
      "AUC: 0.9489235017853688\n",
      "True Positives (TP): 237\n",
      "False Positives (FP): 61\n",
      "True Negatives (TN): 757\n",
      "False Negatives (FN): 41\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t12_35M_UR50D_unified_480_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# List of classifiers with default parameters\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Multilayer Perceptron': MLPClassifier()\n",
    "}\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_scores):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_scores > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_mcc\n",
    "\n",
    "# Evaluate each classifier\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining {clf_name}...\")\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get predicted probabilities or decision scores\n",
    "    if clf_name == 'Support Vector Machine':\n",
    "        # Use decision_function for SVC as probability=True is not default\n",
    "        y_pred_scores_test = clf.decision_function(X_test)\n",
    "    else:\n",
    "        # Use predict_proba for classifiers that support it\n",
    "        y_pred_scores_test = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Optimize the threshold based on MCC\n",
    "    best_threshold_test, best_mcc_test = optimize_threshold(y_test, y_pred_scores_test)\n",
    "    y_pred_test = (y_pred_scores_test > best_threshold_test).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    sensitivity_test = recall_score(y_test, y_pred_test)  # Sensitivity (Recall)\n",
    "    TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "    specificity_test = TN_test / (TN_test + FP_test)\n",
    "    MCC_test = matthews_corrcoef(y_test, y_pred_test)\n",
    "\n",
    "    # Compute AUC\n",
    "    if clf_name == 'Support Vector Machine':\n",
    "        auc_test = roc_auc_score(y_test, y_pred_scores_test)  # Use decision_function scores\n",
    "    else:\n",
    "        auc_test = roc_auc_score(y_test, y_pred_scores_test)\n",
    "\n",
    "    # Compute the correct balanced accuracy\n",
    "    balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n{clf_name} Test Dataset Results:\")\n",
    "    print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "    print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "    print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "    print(f\"Specificity (Sp): {specificity_test}\")\n",
    "    print(f\"MCC: {MCC_test}\")\n",
    "    print(f\"AUC: {auc_test}\")\n",
    "    print(f\"True Positives (TP): {TP_test}\")\n",
    "    print(f\"False Positives (FP): {FP_test}\")\n",
    "    print(f\"True Negatives (TN): {TN_test}\")\n",
    "    print(f\"False Negatives (FN): {FN_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357d591b-7bc5-4a20-9b09-c8942a30747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:49:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Test Dataset Results:\n",
      "Accuracy (ACC): 0.9224452554744526\n",
      "Balanced Accuracy (BACC): 0.8898656136215721\n",
      "Sensitivity (Sn): 0.8237410071942446\n",
      "Specificity (Sp): 0.9559902200488998\n",
      "MCC: 0.7923563239145421\n",
      "AUC: 0.961869624105117\n",
      "True Positives (TP): 229\n",
      "False Positives (FP): 36\n",
      "True Negatives (TN): 782\n",
      "False Negatives (FN): 49\n",
      "Total Positive: 278\n",
      "Total Negative: 818\n",
      "\n",
      "Optimized External Dataset (KELM) Results:\n",
      "Accuracy (ACC): 0.828125\n",
      "Balanced Accuracy (BACC): 0.828125\n",
      "Sensitivity (Sn): 0.6770833333333334\n",
      "Specificity (Sp): 0.9791666666666666\n",
      "MCC: 0.6884115395322729\n",
      "AUC: 0.9019097222222223\n",
      "True Positives (TP): 65\n",
      "False Positives (FP): 2\n",
      "True Negatives (TN): 94\n",
      "False Negatives (FN): 31\n",
      "Total Positive: 96\n",
      "Total Negative: 96\n"
     ]
    }
   ],
   "source": [
    "#uses default parameters\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t12_35M_UR50D_unified_480_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the XGBoost classifier with default parameters\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_probas):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_probas > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        \n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_mcc\n",
    "\n",
    "# Predict probabilities for the test dataset\n",
    "predicted_probas_test = xgb_model.predict_proba(X_test)[:, 1]\n",
    "best_threshold_test, best_mcc_test = optimize_threshold(y_test, predicted_probas_test)\n",
    "predicted_classes_test = (predicted_probas_test > best_threshold_test).astype(int)\n",
    "\n",
    "# Calculate metrics for the test dataset with optimized threshold\n",
    "accuracy_test = accuracy_score(y_test, predicted_classes_test)\n",
    "sensitivity_test = recall_score(y_test, predicted_classes_test)  # Sensitivity (Recall)\n",
    "TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, predicted_classes_test).ravel()\n",
    "specificity_test = TN_test / (TN_test + FP_test)  # Corrected Specificity calculation\n",
    "MCC_test = matthews_corrcoef(y_test, predicted_classes_test)\n",
    "auc_test = roc_auc_score(y_test, predicted_probas_test)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "# Print the adjusted results for the test dataset\n",
    "print(\"\\nOptimized Test Dataset Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "print(f\"Specificity (Sp): {specificity_test}\")\n",
    "print(f\"MCC: {MCC_test}\")\n",
    "print(f\"AUC: {auc_test}\")\n",
    "print(f\"True Positives (TP): {TP_test}\")\n",
    "print(f\"False Positives (FP): {FP_test}\")\n",
    "print(f\"True Negatives (TN): {TN_test}\")\n",
    "print(f\"False Negatives (FN): {FN_test}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive = np.sum(y_test)\n",
    "total_negative = len(y_test) - total_positive\n",
    "print(f\"Total Positive: {total_positive}\")\n",
    "print(f\"Total Negative: {total_negative}\")\n",
    "\n",
    "# Evaluate on the external dataset (KELM)\n",
    "dataset_external = pd.read_csv('kelm_dataset.csv', na_filter=False)\n",
    "X_external_data_name = 'kelm_dataset_esm2_t12_35M_UR50D_unified_480_dimension.csv'\n",
    "X_external_data = pd.read_csv(X_external_data_name, header=0, index_col=0, delimiter=',')\n",
    "X_external = np.array(X_external_data)\n",
    "y_external = np.array(dataset_external['label'])\n",
    "\n",
    "# Normalize the external dataset\n",
    "X_external_normalized = scaler.transform(X_external)\n",
    "\n",
    "# Predict probabilities for external dataset\n",
    "predicted_probas_ext = xgb_model.predict_proba(X_external_normalized)[:, 1]\n",
    "best_threshold_ext, best_mcc_ext = optimize_threshold(y_external, predicted_probas_ext)\n",
    "predicted_classes_ext = (predicted_probas_ext > best_threshold_ext).astype(int)\n",
    "\n",
    "# Calculate metrics for the external dataset with optimized threshold\n",
    "accuracy_ext = accuracy_score(y_external, predicted_classes_ext)\n",
    "sensitivity_ext = recall_score(y_external, predicted_classes_ext)  # Sensitivity (Recall)\n",
    "TN_ext, FP_ext, FN_ext, TP_ext = confusion_matrix(y_external, predicted_classes_ext).ravel()\n",
    "specificity_ext = TN_ext / (TN_ext + FP_ext)  # Corrected Specificity calculation\n",
    "MCC_ext = matthews_corrcoef(y_external, predicted_classes_ext)\n",
    "auc_ext = roc_auc_score(y_external, predicted_probas_ext)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_ext = (sensitivity_ext + specificity_ext) / 2\n",
    "\n",
    "# Print the adjusted results for the external dataset\n",
    "print(\"\\nOptimized External Dataset (KELM) Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_ext}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_ext}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_ext}\")\n",
    "print(f\"Specificity (Sp): {specificity_ext}\")\n",
    "print(f\"MCC: {MCC_ext}\")\n",
    "print(f\"AUC: {auc_ext}\")\n",
    "print(f\"True Positives (TP): {TP_ext}\")\n",
    "print(f\"False Positives (FP): {FP_ext}\")\n",
    "print(f\"True Negatives (TN): {TN_ext}\")\n",
    "print(f\"False Negatives (FN): {FN_ext}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive_ext = np.sum(y_external)\n",
    "total_negative_ext = len(y_external) - total_positive_ext\n",
    "print(f\"Total Positive: {total_positive_ext}\")\n",
    "print(f\"Total Negative: {total_negative_ext}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f957886-5a8a-4dbb-8229-345bff4800df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
