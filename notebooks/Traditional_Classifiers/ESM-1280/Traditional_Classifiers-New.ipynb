{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72b0c09c-173e-4d33-8445-3e5c36db9ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Test Dataset Results:\n",
      "Accuracy (ACC): 0.9142335766423357\n",
      "Balanced Accuracy (BACC): 0.8701166206399185\n",
      "Sensitivity (Sn): 0.7805755395683454\n",
      "Specificity (Sp): 0.9596577017114915\n",
      "MCC: 0.7675602007673235\n",
      "AUC: 0.9562760549506605\n",
      "True Positives (TP): 217\n",
      "False Positives (FP): 33\n",
      "True Negatives (TN): 785\n",
      "False Negatives (FN): 61\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Test Dataset Results:\n",
      "Accuracy (ACC): 0.916058394160584\n",
      "Balanced Accuracy (BACC): 0.8677771719055074\n",
      "Sensitivity (Sn): 0.7697841726618705\n",
      "Specificity (Sp): 0.9657701711491442\n",
      "MCC: 0.7715733095438244\n",
      "AUC: 0.9546687833107597\n",
      "True Positives (TP): 214\n",
      "False Positives (FP): 28\n",
      "True Negatives (TN): 790\n",
      "False Negatives (FN): 64\n",
      "\n",
      "Training Support Vector Machine...\n",
      "\n",
      "Support Vector Machine Test Dataset Results:\n",
      "Accuracy (ACC): 0.9133211678832117\n",
      "Balanced Accuracy (BACC): 0.8516956605864453\n",
      "Sensitivity (Sn): 0.7266187050359713\n",
      "Specificity (Sp): 0.9767726161369193\n",
      "MCC: 0.7627740187508937\n",
      "AUC: 0.9568741095143446\n",
      "True Positives (TP): 202\n",
      "False Positives (FP): 19\n",
      "True Negatives (TN): 799\n",
      "False Negatives (FN): 76\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "\n",
      "K-Nearest Neighbors Test Dataset Results:\n",
      "Accuracy (ACC): 0.9224452554744526\n",
      "Balanced Accuracy (BACC): 0.875617843133806\n",
      "Sensitivity (Sn): 0.7805755395683454\n",
      "Specificity (Sp): 0.9706601466992665\n",
      "MCC: 0.7891938302410412\n",
      "AUC: 0.9372614377935304\n",
      "True Positives (TP): 217\n",
      "False Positives (FP): 24\n",
      "True Negatives (TN): 794\n",
      "False Negatives (FN): 61\n",
      "\n",
      "Training Multilayer Perceptron...\n",
      "\n",
      "Multilayer Perceptron Test Dataset Results:\n",
      "Accuracy (ACC): 0.9087591240875912\n",
      "Balanced Accuracy (BACC): 0.8795095952577792\n",
      "Sensitivity (Sn): 0.8201438848920863\n",
      "Specificity (Sp): 0.9388753056234719\n",
      "MCC: 0.7590191905155582\n",
      "AUC: 0.9516675168422718\n",
      "True Positives (TP): 228\n",
      "False Positives (FP): 50\n",
      "True Negatives (TN): 768\n",
      "False Negatives (FN): 50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t33_650M_UR50D_unified_1280_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# List of classifiers with default parameters\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Multilayer Perceptron': MLPClassifier()\n",
    "}\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_scores):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_scores > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_mcc\n",
    "\n",
    "# Evaluate each classifier\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining {clf_name}...\")\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get predicted probabilities or decision scores\n",
    "    if clf_name == 'Support Vector Machine':\n",
    "        # Use decision_function for SVC as probability=True is not default\n",
    "        y_pred_scores_test = clf.decision_function(X_test)\n",
    "    else:\n",
    "        # Use predict_proba for classifiers that support it\n",
    "        y_pred_scores_test = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Optimize the threshold based on MCC\n",
    "    best_threshold_test, best_mcc_test = optimize_threshold(y_test, y_pred_scores_test)\n",
    "    y_pred_test = (y_pred_scores_test > best_threshold_test).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    sensitivity_test = recall_score(y_test, y_pred_test)  # Sensitivity (Recall)\n",
    "    TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "    specificity_test = TN_test / (TN_test + FP_test)\n",
    "    MCC_test = matthews_corrcoef(y_test, y_pred_test)\n",
    "\n",
    "    # Compute AUC\n",
    "    if clf_name == 'Support Vector Machine':\n",
    "        auc_test = roc_auc_score(y_test, y_pred_scores_test)  # Use decision_function scores\n",
    "    else:\n",
    "        auc_test = roc_auc_score(y_test, y_pred_scores_test)\n",
    "\n",
    "    # Compute the correct balanced accuracy\n",
    "    balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n{clf_name} Test Dataset Results:\")\n",
    "    print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "    print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "    print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "    print(f\"Specificity (Sp): {specificity_test}\")\n",
    "    print(f\"MCC: {MCC_test}\")\n",
    "    print(f\"AUC: {auc_test}\")\n",
    "    print(f\"True Positives (TP): {TP_test}\")\n",
    "    print(f\"False Positives (FP): {FP_test}\")\n",
    "    print(f\"True Negatives (TN): {TN_test}\")\n",
    "    print(f\"False Negatives (FN): {FN_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc384f9-24e1-475d-bfc9-e2a286060660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:02:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Test Dataset Results:\n",
      "Accuracy (ACC): 0.9242700729927007\n",
      "Balanced Accuracy (BACC): 0.8827769080579058\n",
      "Sensitivity (Sn): 0.7985611510791367\n",
      "Specificity (Sp): 0.9669926650366748\n",
      "MCC: 0.7949382543309593\n",
      "AUC: 0.9584440027440152\n",
      "True Positives (TP): 222\n",
      "False Positives (FP): 27\n",
      "True Negatives (TN): 791\n",
      "False Negatives (FN): 56\n",
      "Total Positive: 278\n",
      "Total Negative: 818\n",
      "\n",
      "Optimized External Dataset (KELM) Results:\n",
      "Accuracy (ACC): 0.859375\n",
      "Balanced Accuracy (BACC): 0.859375\n",
      "Sensitivity (Sn): 0.7291666666666666\n",
      "Specificity (Sp): 0.9895833333333334\n",
      "MCC: 0.7444357674125079\n",
      "AUC: 0.9354383680555555\n",
      "True Positives (TP): 70\n",
      "False Positives (FP): 1\n",
      "True Negatives (TN): 95\n",
      "False Negatives (FN): 26\n",
      "Total Positive: 96\n",
      "Total Negative: 96\n"
     ]
    }
   ],
   "source": [
    "#uses default parameters\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t33_650M_UR50D_unified_1280_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the XGBoost classifier with default parameters\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_probas):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_probas > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        \n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_mcc\n",
    "\n",
    "# Predict probabilities for the test dataset\n",
    "predicted_probas_test = xgb_model.predict_proba(X_test)[:, 1]\n",
    "best_threshold_test, best_mcc_test = optimize_threshold(y_test, predicted_probas_test)\n",
    "predicted_classes_test = (predicted_probas_test > best_threshold_test).astype(int)\n",
    "\n",
    "# Calculate metrics for the test dataset with optimized threshold\n",
    "accuracy_test = accuracy_score(y_test, predicted_classes_test)\n",
    "sensitivity_test = recall_score(y_test, predicted_classes_test)  # Sensitivity (Recall)\n",
    "TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, predicted_classes_test).ravel()\n",
    "specificity_test = TN_test / (TN_test + FP_test)  # Corrected Specificity calculation\n",
    "MCC_test = matthews_corrcoef(y_test, predicted_classes_test)\n",
    "auc_test = roc_auc_score(y_test, predicted_probas_test)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "# Print the adjusted results for the test dataset\n",
    "print(\"\\nOptimized Test Dataset Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "print(f\"Specificity (Sp): {specificity_test}\")\n",
    "print(f\"MCC: {MCC_test}\")\n",
    "print(f\"AUC: {auc_test}\")\n",
    "print(f\"True Positives (TP): {TP_test}\")\n",
    "print(f\"False Positives (FP): {FP_test}\")\n",
    "print(f\"True Negatives (TN): {TN_test}\")\n",
    "print(f\"False Negatives (FN): {FN_test}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive = np.sum(y_test)\n",
    "total_negative = len(y_test) - total_positive\n",
    "print(f\"Total Positive: {total_positive}\")\n",
    "print(f\"Total Negative: {total_negative}\")\n",
    "\n",
    "# Evaluate on the external dataset (KELM)\n",
    "dataset_external = pd.read_csv('kelm_dataset.csv', na_filter=False)\n",
    "X_external_data_name = 'kelm_dataset_esm2_t33_650M_UR50D_unified_1280_dimension.csv'\n",
    "X_external_data = pd.read_csv(X_external_data_name, header=0, index_col=0, delimiter=',')\n",
    "X_external = np.array(X_external_data)\n",
    "y_external = np.array(dataset_external['label'])\n",
    "\n",
    "# Normalize the external dataset\n",
    "X_external_normalized = scaler.transform(X_external)\n",
    "\n",
    "# Predict probabilities for external dataset\n",
    "predicted_probas_ext = xgb_model.predict_proba(X_external_normalized)[:, 1]\n",
    "best_threshold_ext, best_mcc_ext = optimize_threshold(y_external, predicted_probas_ext)\n",
    "predicted_classes_ext = (predicted_probas_ext > best_threshold_ext).astype(int)\n",
    "\n",
    "# Calculate metrics for the external dataset with optimized threshold\n",
    "accuracy_ext = accuracy_score(y_external, predicted_classes_ext)\n",
    "sensitivity_ext = recall_score(y_external, predicted_classes_ext)  # Sensitivity (Recall)\n",
    "TN_ext, FP_ext, FN_ext, TP_ext = confusion_matrix(y_external, predicted_classes_ext).ravel()\n",
    "specificity_ext = TN_ext / (TN_ext + FP_ext)  # Corrected Specificity calculation\n",
    "MCC_ext = matthews_corrcoef(y_external, predicted_classes_ext)\n",
    "auc_ext = roc_auc_score(y_external, predicted_probas_ext)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_ext = (sensitivity_ext + specificity_ext) / 2\n",
    "\n",
    "# Print the adjusted results for the external dataset\n",
    "print(\"\\nOptimized External Dataset (KELM) Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_ext}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_ext}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_ext}\")\n",
    "print(f\"Specificity (Sp): {specificity_ext}\")\n",
    "print(f\"MCC: {MCC_ext}\")\n",
    "print(f\"AUC: {auc_ext}\")\n",
    "print(f\"True Positives (TP): {TP_ext}\")\n",
    "print(f\"False Positives (FP): {FP_ext}\")\n",
    "print(f\"True Negatives (TN): {TN_ext}\")\n",
    "print(f\"False Negatives (FN): {FN_ext}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive_ext = np.sum(y_external)\n",
    "total_negative_ext = len(y_external) - total_positive_ext\n",
    "print(f\"Total Positive: {total_positive_ext}\")\n",
    "print(f\"Total Negative: {total_negative_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc470990-993a-42c4-82f7-15d43d450acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
