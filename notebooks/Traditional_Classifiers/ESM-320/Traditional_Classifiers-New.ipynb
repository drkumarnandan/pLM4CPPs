{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f51a16-617c-4527-a3d8-33445d69fae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Test Dataset Results:\n",
      "Accuracy (ACC): 0.906021897810219\n",
      "Balanced Accuracy (BACC): 0.8574915129021478\n",
      "Sensitivity (Sn): 0.7589928057553957\n",
      "Specificity (Sp): 0.9559902200488998\n",
      "MCC: 0.744547585368083\n",
      "AUC: 0.9413071010184517\n",
      "True Positives (TP): 211\n",
      "False Positives (FP): 36\n",
      "True Negatives (TN): 782\n",
      "False Negatives (FN): 67\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Test Dataset Results:\n",
      "Accuracy (ACC): 0.916058394160584\n",
      "Balanced Accuracy (BACC): 0.8642152292835659\n",
      "Sensitivity (Sn): 0.7589928057553957\n",
      "Specificity (Sp): 0.969437652811736\n",
      "MCC: 0.7710488961664522\n",
      "AUC: 0.9544928849096762\n",
      "True Positives (TP): 211\n",
      "False Positives (FP): 25\n",
      "True Negatives (TN): 793\n",
      "False Negatives (FN): 67\n",
      "\n",
      "Training Support Vector Machine...\n",
      "\n",
      "Support Vector Machine Test Dataset Results:\n",
      "Accuracy (ACC): 0.8978102189781022\n",
      "Balanced Accuracy (BACC): 0.8282440062619831\n",
      "Sensitivity (Sn): 0.6870503597122302\n",
      "Specificity (Sp): 0.969437652811736\n",
      "MCC: 0.7180548805765267\n",
      "AUC: 0.9536111941742449\n",
      "True Positives (TP): 191\n",
      "False Positives (FP): 25\n",
      "True Negatives (TN): 793\n",
      "False Negatives (FN): 87\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "\n",
      "K-Nearest Neighbors Test Dataset Results:\n",
      "Accuracy (ACC): 0.926094890510949\n",
      "Balanced Accuracy (BACC): 0.886374030360064\n",
      "Sensitivity (Sn): 0.8057553956834532\n",
      "Specificity (Sp): 0.9669926650366748\n",
      "MCC: 0.8001506427101813\n",
      "AUC: 0.9514432463808904\n",
      "True Positives (TP): 224\n",
      "False Positives (FP): 27\n",
      "True Negatives (TN): 791\n",
      "False Negatives (FN): 54\n",
      "\n",
      "Training Multilayer Perceptron...\n",
      "\n",
      "Multilayer Perceptron Test Dataset Results:\n",
      "Accuracy (ACC): 0.9051094890510949\n",
      "Balanced Accuracy (BACC): 0.8936870063851119\n",
      "Sensitivity (Sn): 0.8705035971223022\n",
      "Specificity (Sp): 0.9168704156479217\n",
      "MCC: 0.7606554944994576\n",
      "AUC: 0.9478197393185696\n",
      "True Positives (TP): 242\n",
      "False Positives (FP): 68\n",
      "True Negatives (TN): 750\n",
      "False Negatives (FN): 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# List of classifiers with default parameters\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Multilayer Perceptron': MLPClassifier()\n",
    "}\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_scores):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_scores > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_mcc\n",
    "\n",
    "# Evaluate each classifier\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining {clf_name}...\")\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get predicted probabilities or decision scores\n",
    "    if clf_name == 'Support Vector Machine':\n",
    "        # Use decision_function for SVC as probability=True is not default\n",
    "        y_pred_scores_test = clf.decision_function(X_test)\n",
    "    else:\n",
    "        # Use predict_proba for classifiers that support it\n",
    "        y_pred_scores_test = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Optimize the threshold based on MCC\n",
    "    best_threshold_test, best_mcc_test = optimize_threshold(y_test, y_pred_scores_test)\n",
    "    y_pred_test = (y_pred_scores_test > best_threshold_test).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    sensitivity_test = recall_score(y_test, y_pred_test)  # Sensitivity (Recall)\n",
    "    TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "    specificity_test = TN_test / (TN_test + FP_test)\n",
    "    MCC_test = matthews_corrcoef(y_test, y_pred_test)\n",
    "\n",
    "    # Compute AUC\n",
    "    if clf_name == 'Support Vector Machine':\n",
    "        auc_test = roc_auc_score(y_test, y_pred_scores_test)  # Use decision_function scores\n",
    "    else:\n",
    "        auc_test = roc_auc_score(y_test, y_pred_scores_test)\n",
    "\n",
    "    # Compute the correct balanced accuracy\n",
    "    balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n{clf_name} Test Dataset Results:\")\n",
    "    print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "    print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "    print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "    print(f\"Specificity (Sp): {specificity_test}\")\n",
    "    print(f\"MCC: {MCC_test}\")\n",
    "    print(f\"AUC: {auc_test}\")\n",
    "    print(f\"True Positives (TP): {TP_test}\")\n",
    "    print(f\"False Positives (FP): {FP_test}\")\n",
    "    print(f\"True Negatives (TN): {TN_test}\")\n",
    "    print(f\"False Negatives (FN): {FN_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "177eed95-6644-4fd8-afe4-8f5fadf41348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:10:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Test Dataset Results:\n",
      "Accuracy (ACC): 0.9215328467153284\n",
      "Balanced Accuracy (BACC): 0.8809431672266099\n",
      "Sensitivity (Sn): 0.7985611510791367\n",
      "Specificity (Sp): 0.9633251833740831\n",
      "MCC: 0.7878031990512089\n",
      "AUC: 0.961478250162706\n",
      "True Positives (TP): 222\n",
      "False Positives (FP): 30\n",
      "True Negatives (TN): 788\n",
      "False Negatives (FN): 56\n",
      "Total Positive: 278\n",
      "Total Negative: 818\n",
      "\n",
      "Optimized External Dataset (KELM) Results:\n",
      "Accuracy (ACC): 0.8385416666666666\n",
      "Balanced Accuracy (BACC): 0.8385416666666667\n",
      "Sensitivity (Sn): 0.7083333333333334\n",
      "Specificity (Sp): 0.96875\n",
      "MCC: 0.7012800707509134\n",
      "AUC: 0.9215494791666666\n",
      "True Positives (TP): 68\n",
      "False Positives (FP): 3\n",
      "True Negatives (TN): 93\n",
      "False Negatives (FN): 28\n",
      "Total Positive: 96\n",
      "Total Negative: 96\n"
     ]
    }
   ],
   "source": [
    "#uses default parameters\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel('Final_non_redundant_sequences.xlsx', na_filter=False)\n",
    "X_data_name = 'whole_sample_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_data = pd.read_csv(X_data_name, header=0, index_col=0, delimiter=',')\n",
    "X = np.array(X_data)\n",
    "y = np.array(dataset['label'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the XGBoost classifier with default parameters\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Function to optimize threshold based on MCC\n",
    "def optimize_threshold(y_true, y_pred_probas):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    best_mcc = -1\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_probas > threshold).astype(int)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        \n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_mcc\n",
    "\n",
    "# Predict probabilities for the test dataset\n",
    "predicted_probas_test = xgb_model.predict_proba(X_test)[:, 1]\n",
    "best_threshold_test, best_mcc_test = optimize_threshold(y_test, predicted_probas_test)\n",
    "predicted_classes_test = (predicted_probas_test > best_threshold_test).astype(int)\n",
    "\n",
    "# Calculate metrics for the test dataset with optimized threshold\n",
    "accuracy_test = accuracy_score(y_test, predicted_classes_test)\n",
    "sensitivity_test = recall_score(y_test, predicted_classes_test)  # Sensitivity (Recall)\n",
    "TN_test, FP_test, FN_test, TP_test = confusion_matrix(y_test, predicted_classes_test).ravel()\n",
    "specificity_test = TN_test / (TN_test + FP_test)  # Corrected Specificity calculation\n",
    "MCC_test = matthews_corrcoef(y_test, predicted_classes_test)\n",
    "auc_test = roc_auc_score(y_test, predicted_probas_test)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_test = (sensitivity_test + specificity_test) / 2\n",
    "\n",
    "# Print the adjusted results for the test dataset\n",
    "print(\"\\nOptimized Test Dataset Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_test}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_test}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_test}\")\n",
    "print(f\"Specificity (Sp): {specificity_test}\")\n",
    "print(f\"MCC: {MCC_test}\")\n",
    "print(f\"AUC: {auc_test}\")\n",
    "print(f\"True Positives (TP): {TP_test}\")\n",
    "print(f\"False Positives (FP): {FP_test}\")\n",
    "print(f\"True Negatives (TN): {TN_test}\")\n",
    "print(f\"False Negatives (FN): {FN_test}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive = np.sum(y_test)\n",
    "total_negative = len(y_test) - total_positive\n",
    "print(f\"Total Positive: {total_positive}\")\n",
    "print(f\"Total Negative: {total_negative}\")\n",
    "\n",
    "# Evaluate on the external dataset (KELM)\n",
    "dataset_external = pd.read_csv('kelm_dataset.csv', na_filter=False)\n",
    "X_external_data_name = 'kelm_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
    "X_external_data = pd.read_csv(X_external_data_name, header=0, index_col=0, delimiter=',')\n",
    "X_external = np.array(X_external_data)\n",
    "y_external = np.array(dataset_external['label'])\n",
    "\n",
    "# Normalize the external dataset\n",
    "X_external_normalized = scaler.transform(X_external)\n",
    "\n",
    "# Predict probabilities for external dataset\n",
    "predicted_probas_ext = xgb_model.predict_proba(X_external_normalized)[:, 1]\n",
    "best_threshold_ext, best_mcc_ext = optimize_threshold(y_external, predicted_probas_ext)\n",
    "predicted_classes_ext = (predicted_probas_ext > best_threshold_ext).astype(int)\n",
    "\n",
    "# Calculate metrics for the external dataset with optimized threshold\n",
    "accuracy_ext = accuracy_score(y_external, predicted_classes_ext)\n",
    "sensitivity_ext = recall_score(y_external, predicted_classes_ext)  # Sensitivity (Recall)\n",
    "TN_ext, FP_ext, FN_ext, TP_ext = confusion_matrix(y_external, predicted_classes_ext).ravel()\n",
    "specificity_ext = TN_ext / (TN_ext + FP_ext)  # Corrected Specificity calculation\n",
    "MCC_ext = matthews_corrcoef(y_external, predicted_classes_ext)\n",
    "auc_ext = roc_auc_score(y_external, predicted_probas_ext)\n",
    "\n",
    "# Compute the correct balanced accuracy\n",
    "balanced_accuracy_ext = (sensitivity_ext + specificity_ext) / 2\n",
    "\n",
    "# Print the adjusted results for the external dataset\n",
    "print(\"\\nOptimized External Dataset (KELM) Results:\")\n",
    "print(f\"Accuracy (ACC): {accuracy_ext}\")\n",
    "print(f\"Balanced Accuracy (BACC): {balanced_accuracy_ext}\")\n",
    "print(f\"Sensitivity (Sn): {sensitivity_ext}\")\n",
    "print(f\"Specificity (Sp): {specificity_ext}\")\n",
    "print(f\"MCC: {MCC_ext}\")\n",
    "print(f\"AUC: {auc_ext}\")\n",
    "print(f\"True Positives (TP): {TP_ext}\")\n",
    "print(f\"False Positives (FP): {FP_ext}\")\n",
    "print(f\"True Negatives (TN): {TN_ext}\")\n",
    "print(f\"False Negatives (FN): {FN_ext}\")\n",
    "\n",
    "# Print the total positive and total negative\n",
    "total_positive_ext = np.sum(y_external)\n",
    "total_negative_ext = len(y_external) - total_positive_ext\n",
    "print(f\"Total Positive: {total_positive_ext}\")\n",
    "print(f\"Total Negative: {total_negative_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac593a1-cfc5-453b-936d-0f171cff44c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
